[
    {
        "PMID": "39090091",
        "Title": "Neural representational geometries reflect behavioral differences in monkeys and recurrent neural networks.",
        "Abstract": "Animals likely use a variety of strategies to solve laboratory tasks. Traditionally, combined analysis of behavioral and neural recording data across subjects employing different strategies may obscure important signals and give confusing results. Hence, it is essential to develop techniques that can infer strategy at the single-subject level. We analyzed an experiment in which two male monkeys performed a visually cued rule-based task. The analysis of their performance shows no indication that they used a different strategy. However, when we examined the geometry of stimulus representations in the state space of the neural activities recorded in dorsolateral prefrontal cortex, we found striking differences between the two monkeys. Our purely neural results induced us to reanalyze the behavior. The new analysis showed that the differences in representational geometry are associated with differences in the reaction times, revealing behavioral differences we were unaware of. All these analyses suggest that the monkeys are using different strategies. Finally, using recurrent neural network models trained to perform the same task, we show that these strategies correlate with the amount of training, suggesting a possible explanation for the observed neural and behavioral differences.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Male",
            "Behavior, Animal",
            "Prefrontal Cortex",
            "Macaca mulatta",
            "Reaction Time",
            "Neural Networks, Computer",
            "Nerve Net",
            "Cues",
            "Neurons",
            "Models, Neurological"
        ],
        "Authors": [
            {
                "First Name": "Valeria",
                "Last Name": "Fascianelli",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, USA. vf2266@columbia.edu."
            },
            {
                "First Name": "Aldo",
                "Last Name": "Battista",
                "Affiliation": "Center for Neural Science, New York University, New York, NY, USA."
            },
            {
                "First Name": "Fabio",
                "Last Name": "Stefanini",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Satoshi",
                "Last Name": "Tsujimoto",
                "Affiliation": "SixthFactor Pte. Ltd, Singapore, Singapore."
            },
            {
                "First Name": "Aldo",
                "Last Name": "Genovesio",
                "Affiliation": "Department of Physiology and Pharmacology, Sapienza University of Rome, Rome, Italy. aldo.genovesio@uniroma1.it."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, USA. sf2237@columbia.edu."
            }
        ],
        "Journal": "Nature communications",
        "PubDate": "2024"
    },
    {
        "PMID": "39019928",
        "Title": "Author Correction: Perirhinal cortex learns a predictive map of the task environment.",
        "Abstract": null,
        "Keywords": [],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "David G",
                "Last Name": "Lee",
                "Affiliation": "Department of Biomedical Engineering, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Caroline A",
                "Last Name": "McLachlan",
                "Affiliation": "Center for Neurophotonics, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Ramon",
                "Last Name": "Nogueira",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, 10027, USA."
            },
            {
                "First Name": "Osung",
                "Last Name": "Kwon",
                "Affiliation": "Center for Neurophotonics, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Alanna E",
                "Last Name": "Carey",
                "Affiliation": "Center for Neurophotonics, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Garrett",
                "Last Name": "House",
                "Affiliation": "Department of Biology, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Gavin D",
                "Last Name": "Lagani",
                "Affiliation": "Department of Biology, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Danielle",
                "Last Name": "LaMay",
                "Affiliation": "Department of Biology, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, 10027, USA."
            },
            {
                "First Name": "Jerry L",
                "Last Name": "Chen",
                "Affiliation": "Department of Biomedical Engineering, Boston University, Boston, MA, 02215, USA. jerry@chen-lab.org."
            }
        ],
        "Journal": "Nature communications",
        "PubDate": "2024"
    },
    {
        "PMID": "38956015",
        "Title": "Perirhinal cortex learns a predictive map of the task environment.",
        "Abstract": "Goal-directed tasks involve acquiring an internal model, known as a predictive map, of relevant stimuli and associated outcomes to guide behavior. Here, we identified neural signatures of a predictive map of task behavior in perirhinal cortex (Prh). Mice learned to perform a tactile working memory task by classifying sequential whisker stimuli over multiple training stages. Chronic two-photon calcium imaging, population analysis, and computational modeling revealed that Prh encodes stimulus features as sensory prediction errors. Prh forms stable stimulus-outcome associations that can progressively be decoded earlier in the trial as training advances and that generalize as animals learn new contingencies. Stimulus-outcome associations are linked to prospective network activity encoding possible expected outcomes. This link is mediated by cholinergic signaling to guide task performance, demonstrated by acetylcholine imaging and systemic pharmacological perturbation. We propose that Prh combines error-driven and map-like properties to acquire a predictive map of learned task behavior.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Mice",
            "Perirhinal Cortex",
            "Memory, Short-Term",
            "Male",
            "Learning",
            "Mice, Inbred C57BL",
            "Vibrissae",
            "Acetylcholine",
            "Behavior, Animal",
            "Female"
        ],
        "Authors": [
            {
                "First Name": "David G",
                "Last Name": "Lee",
                "Affiliation": "Department of Biomedical Engineering, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Caroline A",
                "Last Name": "McLachlan",
                "Affiliation": "Center for Neurophotonics, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Ramon",
                "Last Name": "Nogueira",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, 10027, USA."
            },
            {
                "First Name": "Osung",
                "Last Name": "Kwon",
                "Affiliation": "Center for Neurophotonics, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Alanna E",
                "Last Name": "Carey",
                "Affiliation": "Center for Neurophotonics, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Garrett",
                "Last Name": "House",
                "Affiliation": "Department of Biology, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Gavin D",
                "Last Name": "Lagani",
                "Affiliation": "Department of Biology, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Danielle",
                "Last Name": "LaMay",
                "Affiliation": "Department of Biology, Boston University, Boston, MA, 02215, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, 10027, USA."
            },
            {
                "First Name": "Jerry L",
                "Last Name": "Chen",
                "Affiliation": "Department of Biomedical Engineering, Boston University, Boston, MA, 02215, USA. jerry@chen-lab.org."
            }
        ],
        "Journal": "Nature communications",
        "PubDate": "2024"
    },
    {
        "PMID": "38750353",
        "Title": "Temporal multiplexing of perception and memory codes in IT cortex.",
        "Abstract": "A central assumption of neuroscience is that long-term memories are represented by the same brain areas that encode sensory stimuli",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Face",
            "Facial Recognition",
            "Macaca mulatta",
            "Memory, Long-Term",
            "Neurons",
            "Perirhinal Cortex",
            "Photic Stimulation",
            "Recognition, Psychology",
            "Temporal Lobe",
            "Rotation"
        ],
        "Authors": [
            {
                "First Name": "Liang",
                "Last Name": "She",
                "Affiliation": "Division of Biology and Biological Engineering, Caltech, Pasadena, CA, USA. liangshe@caltech.edu."
            },
            {
                "First Name": "Marcus K",
                "Last Name": "Benna",
                "Affiliation": "Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York City, NY, USA."
            },
            {
                "First Name": "Yuelin",
                "Last Name": "Shi",
                "Affiliation": "Division of Biology and Biological Engineering, Caltech, Pasadena, CA, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York City, NY, USA."
            },
            {
                "First Name": "Doris Y",
                "Last Name": "Tsao",
                "Affiliation": "Division of Biology and Biological Engineering, Caltech, Pasadena, CA, USA. dortsao@berkeley.edu."
            }
        ],
        "Journal": "Nature",
        "PubDate": "2024"
    },
    {
        "PMID": "38729151",
        "Title": "Mixed selectivity: Cellular computations for complexity.",
        "Abstract": "The property of mixed selectivity has been discussed at a computational level and offers a strategy to maximize computational power by adding versatility to the functional role of each neuron. Here, we offer a biologically grounded implementational-level mechanistic explanation for mixed selectivity in neural circuits. We define pure, linear, and nonlinear mixed selectivity and discuss how these response properties can be obtained in simple neural circuits. Neurons that respond to multiple, statistically independent variables display mixed selectivity. If their activity can be expressed as a weighted sum, then they exhibit linear mixed selectivity; otherwise, they exhibit nonlinear mixed selectivity. Neural representations based on diverse nonlinear mixed selectivity are high dimensional; hence, they confer enormous flexibility to a simple downstream readout neural circuit. However, a simple neural circuit cannot possibly encode all possible mixtures of variables simultaneously, as this would require a combinatorially large number of mixed selectivity neurons. Gating mechanisms like oscillations and neuromodulation can solve this problem by dynamically selecting which variables are mixed and transmitted to the readout.",
        "Keywords": [
            "brain",
            "circuits",
            "coding",
            "cognition",
            "computations",
            "gating",
            "mixed selectivity",
            "neuromodulation",
            "neuron",
            "oscillations"
        ],
        "MeSH terms": [
            "Neurons",
            "Models, Neurological",
            "Animals",
            "Nerve Net",
            "Humans",
            "Nonlinear Dynamics"
        ],
        "Authors": [
            {
                "First Name": "Kay M",
                "Last Name": "Tye",
                "Affiliation": "Salk Institute for Biological Studies, La Jolla, CA, USA; Howard Hughes Medical Institute, La Jolla, CA; Department of Neurobiology, School of Biological Sciences, University of California, San Diego, La Jolla, CA 92093, USA; Kavli Institute for Brain and Mind, San Diego, CA, USA. Electronic address: tye@salk.edu."
            },
            {
                "First Name": "Earl K",
                "Last Name": "Miller",
                "Affiliation": "The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. Electronic address: ekmiller@mit.edu."
            },
            {
                "First Name": "Felix H",
                "Last Name": "Taschbach",
                "Affiliation": "Salk Institute for Biological Studies, La Jolla, CA, USA; Biological Science Graduate Program, University of California, San Diego, La Jolla, CA 92093, USA; Department of Neurobiology, School of Biological Sciences, University of California, San Diego, La Jolla, CA 92093, USA. Electronic address: ftaschbach@salk.edu."
            },
            {
                "First Name": "Marcus K",
                "Last Name": "Benna",
                "Affiliation": "Department of Neurobiology, School of Biological Sciences, University of California, San Diego, La Jolla, CA 92093, USA. Electronic address: mbenna@ucsd.edu."
            },
            {
                "First Name": "Mattia",
                "Last Name": "Rigotti",
                "Affiliation": "IBM Research, Zurich, Switzerland. Electronic address: mr2226@columbia.edu."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA; Department of Neuroscience, Columbia University, New York, NY, USA; Kavli Institute for Brain Science, Columbia University, New York, NY, USA. Electronic address: sf2237@columbia.edu."
            }
        ],
        "Journal": "Neuron",
        "PubDate": "2024"
    },
    {
        "PMID": "38553340",
        "Title": "Computational role of structure in neural activity and connectivity.",
        "Abstract": "One major challenge of neuroscience is identifying structure in seemingly disorganized neural activity. Different types of structure have different computational implications that can help neuroscientists understand the functional role of a particular brain area. Here, we outline a unified approach to characterize structure by inspecting the representational geometry and the modularity properties of the recorded activity and show that a similar approach can also reveal structure in connectivity. We start by setting up a general framework for determining geometry and modularity in activity and connectivity and relating these properties with computations performed by the network. We then use this framework to review the types of structure found in recent studies of model networks performing three classes of computations.",
        "Keywords": [
            "neural coding",
            "neural network models",
            "neural representations"
        ],
        "MeSH terms": [
            "Humans",
            "Brain",
            "Nerve Net",
            "Models, Neurological",
            "Animals",
            "Connectome"
        ],
        "Authors": [
            {
                "First Name": "Srdjan",
                "Last Name": "Ostojic",
                "Affiliation": "Laboratoire de Neurosciences Cognitives et Computationnelles, INSERM U960, Ecole Normale Superieure - PSL Research University, 75005 Paris, France. Electronic address: srdjan.ostojic@ens.psl.eu."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA; Department of Neuroscience, Columbia University, New York, NY, USA; Kavli Institute for Brain Science, Columbia University, New York, NY, USA."
            }
        ],
        "Journal": "Trends in cognitive sciences",
        "PubDate": "2024"
    },
    {
        "PMID": "38382521",
        "Title": "Tuned geometries of hippocampal representations meet the computational demands of social memory.",
        "Abstract": "Social memory consists of two processes: the detection of familiar compared with novel conspecifics and the detailed recollection of past social episodes. We investigated the neural bases for these processes using calcium imaging of dorsal CA2 hippocampal pyramidal neurons, known to be important for social memory, during social/spatial encounters with novel conspecifics and familiar littermates. Whereas novel individuals were represented in a low-dimensional geometry that allows for generalization of social identity across different spatial locations and of location across different identities, littermates were represented in a higher-dimensional geometry that supports high-capacity memory storage. Moreover, familiarity was represented in an abstract format, independent of individual identity. The degree to which familiarity increased the dimensionality of CA2 representations for individual mice predicted their performance in a social novelty recognition memory test. Thus, by tuning the geometry of structured neural activity, CA2 is able to meet the demands of distinct social memory processes.",
        "Keywords": [
            "CA2",
            "abstraction",
            "familiarity",
            "geometry",
            "hippocampus",
            "identity",
            "novelty",
            "recollection",
            "social memory",
            "social recognition"
        ],
        "MeSH terms": [
            "Mice",
            "Animals",
            "Hippocampus",
            "Recognition, Psychology",
            "Memory",
            "Pyramidal Cells"
        ],
        "Authors": [
            {
                "First Name": "Lara M",
                "Last Name": "Boyle",
                "Affiliation": "Department of Neuroscience, Vagelos College of Physicians and Surgeons, Columbia University Irving Medical Center, New York, NY 10027, USA."
            },
            {
                "First Name": "Lorenzo",
                "Last Name": "Posani",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Sarah",
                "Last Name": "Irfan",
                "Affiliation": "Barnard College, New York, NY 10027, USA."
            },
            {
                "First Name": "Steven A",
                "Last Name": "Siegelbaum",
                "Affiliation": "Department of Neuroscience, Vagelos College of Physicians and Surgeons, Columbia University Irving Medical Center, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA; Department of Pharmacology, Vagelos College of Physicians and Surgeons, Columbia University Irving Medical Center, New York, NY 10032, USA; Kavli Institute for Brain Science, Columbia University, New York, NY 10027, USA. Electronic address: sas8@cumc.columbia.edu."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Department of Neuroscience, Vagelos College of Physicians and Surgeons, Columbia University Irving Medical Center, New York, NY 10027, USA; Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA; Kavli Institute for Brain Science, Columbia University, New York, NY 10027, USA. Electronic address: sf2237@columbia.edu."
            }
        ],
        "Journal": "Neuron",
        "PubDate": "2024"
    },
    {
        "PMID": "38343839",
        "Title": "Identifying and modulating neural signatures of stress susceptibility and resilience enables control of anhedonia.",
        "Abstract": "Anhedonia is a core aspect of major depressive disorder. Traditionally viewed as a blunted emotional state in which individuals are unable to experience joy, anhedonia also diminishes the drive to seek rewards and the ability to value and learn about them ",
        "Keywords": [],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Frances",
                "Last Name": "Xia",
                "Affiliation": "Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, USA."
            },
            {
                "First Name": "Valeria",
                "Last Name": "Fascianelli",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, NY, USA."
            },
            {
                "First Name": "Nina",
                "Last Name": "Vishwakarma",
                "Affiliation": "Neuroscience Graduate Program, University of California, San Francisco, San Francisco, USA."
            },
            {
                "First Name": "Frances Grace",
                "Last Name": "Ghinger",
                "Affiliation": "Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, NY, USA."
            },
            {
                "First Name": "Mazen A",
                "Last Name": "Kheirbek",
                "Affiliation": "Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, USA."
            }
        ],
        "Journal": "Research square",
        "PubDate": "2024"
    },
    {
        "PMID": "37986878",
        "Title": "Abstract representations emerge in human hippocampal neurons during inference behavior.",
        "Abstract": "",
        "Keywords": [],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Hristos S",
                "Last Name": "Courellis",
                "Affiliation": ""
            },
            {
                "First Name": "Juri",
                "Last Name": "Mixha",
                "Affiliation": ""
            },
            {
                "First Name": "Araceli R",
                "Last Name": "Cardenas",
                "Affiliation": ""
            },
            {
                "First Name": "Daniel",
                "Last Name": "Kimmel",
                "Affiliation": ""
            },
            {
                "First Name": "Chrystal M",
                "Last Name": "Reed",
                "Affiliation": ""
            },
            {
                "First Name": "Taufik A",
                "Last Name": "Valiante",
                "Affiliation": ""
            },
            {
                "First Name": "C Daniel",
                "Last Name": "Salzman",
                "Affiliation": ""
            },
            {
                "First Name": "Adam N",
                "Last Name": "Mamelak",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Ueli",
                "Last Name": "Rutishauser",
                "Affiliation": ""
            }
        ],
        "Journal": "bioRxiv : the preprint server for biology",
        "PubDate": "2023"
    },
    {
        "PMID": "37961124",
        "Title": "Neural signatures of stress susceptibility and resilience in the amygdala-hippocampal network.",
        "Abstract": "The neural dynamics that underlie divergent anhedonic responses to stress remain unclear. Here, we identified neuronal dynamics in an amygdala-hippocampal circuit that distinguish stress resilience and susceptibility. In a reward-choice task, basolateral amygdala (BLA) activity in resilient mice showed enhanced discrimination of upcoming reward choices. In contrast, a rumination-like signature emerged in the BLA of susceptible mice; a linear decoder could classify the intention to switch or stay on a previously chosen reward. Spontaneous activity in the BLA of susceptible mice was higher dimensional than controls, reflecting the exploration of a larger number of distinct neural states. Manipulation of vCA1-BLA inputs rescued dysfunctional neural dynamics and anhedonia in susceptible mice, suggesting that targeting this pathway can enhance BLA circuit function and ameliorate of depression-related behaviors.",
        "Keywords": [],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Frances",
                "Last Name": "Xia",
                "Affiliation": "Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, USA."
            },
            {
                "First Name": "Valeria",
                "Last Name": "Fascianelli",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, NY, USA."
            },
            {
                "First Name": "Nina",
                "Last Name": "Vishwakarma",
                "Affiliation": "Neuroscience Graduate Program, University of California, San Francisco, San Francisco, USA."
            },
            {
                "First Name": "Frances Grace",
                "Last Name": "Ghinger",
                "Affiliation": "Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, NY, USA."
            },
            {
                "First Name": "Mazen A",
                "Last Name": "Kheirbek",
                "Affiliation": "Department of Psychiatry and Behavioral Sciences, University of California, San Francisco, San Francisco, USA."
            }
        ],
        "Journal": "bioRxiv : the preprint server for biology",
        "PubDate": "2023"
    },
    {
        "PMID": "37808689",
        "Title": "Ventral CA1 Population Codes for Anxiety.",
        "Abstract": "The ventral hippocampus is a critical node in the distributed brain network that controls anxiety. Using miniature microscopy and calcium imaging, we recorded ventral CA1 (vCA1) neurons in freely moving mice as they explored variants of classic behavioral assays for anxiety. Unsupervised behavioral segmentation revealed clusters of behavioral motifs that corresponded to exploratory and vigilance-like states. We discovered multiple vCA1 population codes that represented the anxiogenic features of the environment, such as bright light and openness, as well as the moment-to-moment anxiety state of the animals. These population codes possessed distinct generalization properties: neural representations of anxiogenic features were different for open field and elevated plus/zero maze tasks, while neural representations of moment-to-moment anxiety state were similar across both experimental contexts. Our results suggest that anxiety is not tied to the aversive compartments of these mazes but is rather defined by a behavioral state and its corresponding population code that generalizes across environments.",
        "Keywords": [],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Sean C",
                "Last Name": "Lim",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Ren\u00e9",
                "Last Name": "Hen",
                "Affiliation": ""
            }
        ],
        "Journal": "bioRxiv : the preprint server for biology",
        "PubDate": "2023"
    },
    {
        "PMID": "37790470",
        "Title": "The representational geometry of emotional states in basolateral amygdala.",
        "Abstract": "Sensory stimuli associated with aversive outcomes cause multiple behavioral responses related to an animal's evolving emotional state, but neural mechanisms underlying these processes remain unclear. Here aversive stimuli were presented to mice, eliciting two responses reflecting fear and flight to safety: tremble and ingress into a virtual burrow. Inactivation of basolateral amygdala (BLA) eliminated differential responses to aversive and neutral stimuli without eliminating responses themselves, suggesting BLA signals valence, not motor commands. However, two-photon imaging revealed that neurons typically exhibited mixed selectivity for stimulus identity, valence, tremble and/or ingress. Despite heterogeneous selectivity, BLA representational geometry was lower-dimensional when encoding valence, tremble and safety, enabling generalization of emotions across conditions. Further, tremble and valence coding directions were orthogonal, allowing linear readouts to specialize. Thus BLA representational geometry confers two computational properties that identify specialized neural circuits encoding variables describing emotional states: generalization across conditions, and readouts lacking interference from other readouts.",
        "Keywords": [],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Pia-Kelsey",
                "Last Name": "O'Neill",
                "Affiliation": ""
            },
            {
                "First Name": "Lorenzo",
                "Last Name": "Posani",
                "Affiliation": ""
            },
            {
                "First Name": "Jozsef",
                "Last Name": "Meszaros",
                "Affiliation": ""
            },
            {
                "First Name": "Phebe",
                "Last Name": "Warren",
                "Affiliation": ""
            },
            {
                "First Name": "Carl E",
                "Last Name": "Schoonover",
                "Affiliation": ""
            },
            {
                "First Name": "Andrew J P",
                "Last Name": "Fink",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "C Daniel",
                "Last Name": "Salzman",
                "Affiliation": ""
            }
        ],
        "Journal": "bioRxiv : the preprint server for biology",
        "PubDate": "2024"
    },
    {
        "PMID": "37693175",
        "Title": "The computational role of structure in neural activity and connectivity.",
        "Abstract": "One major challenge of neuroscience is finding interesting structures in a seemingly disorganized neural activity. Often these structures have computational implications that help to understand the functional role of a particular brain area. Here we outline a unified approach to characterize these structures by inspecting the representational geometry and the modularity properties of the recorded activity, and show that this approach can also reveal structures in connectivity. We start by setting up a general framework for determining geometry and modularity in activity and connectivity and relating these properties with computations performed by the network. We then use this framework to review the types of structure found in recent works on model networks performing three classes of computations.",
        "Keywords": [],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Srdjan",
                "Last Name": "Ostojic",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "ArXiv",
        "PubDate": "2023"
    },
    {
        "PMID": "36993645",
        "Title": "PERIRHINAL CORTEX LEARNS A PREDICTIVE MAP (INTERNAL MODEL) OF THE TASK ENVIRONMENT.",
        "Abstract": "Goal-directed tasks involve acquiring an internal model, known as a predictive map, of relevant stimuli and associated outcomes to guide behavior. Here, we identified neural signatures of a predictive map of task behavior in perirhinal cortex (Prh). Mice learned to perform a tactile working memory task by classifying sequential whisker stimuli over multiple training stages. Chemogenetic inactivation demonstrated that Prh is involved in task learning. Chronic two-photon calcium imaging, population analysis, and computational modeling revealed that Prh encodes stimulus features as sensory prediction errors. Prh forms stable stimulus-outcome associations that expand in a retrospective manner and generalize as animals learn new contingencies. Stimulus-outcome associations are linked to prospective network activity encoding possible expected outcomes. This link is mediated by cholinergic signaling to guide task performance, demonstrated by acetylcholine imaging and perturbation. We propose that Prh combines error-driven and map-like properties to acquire a predictive map of learned task behavior.",
        "Keywords": [],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "David G",
                "Last Name": "Lee",
                "Affiliation": "Department of Biomedical Engineering, Boston University, Boston MA 02215, USA."
            },
            {
                "First Name": "Caroline A",
                "Last Name": "McLachlan",
                "Affiliation": "Center for Neurophotonics, Boston University, Boston MA 02215, USA."
            },
            {
                "First Name": "Ramon",
                "Last Name": "Nogueira",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Osung",
                "Last Name": "Kwon",
                "Affiliation": "Center for Neurophotonics, Boston University, Boston MA 02215, USA."
            },
            {
                "First Name": "Alanna E",
                "Last Name": "Carey",
                "Affiliation": "Center for Neurophotonics, Boston University, Boston MA 02215, USA."
            },
            {
                "First Name": "Garrett",
                "Last Name": "House",
                "Affiliation": "Department of Biology, Boston University, Boston MA 02215, USA."
            },
            {
                "First Name": "Gavin D",
                "Last Name": "Lagani",
                "Affiliation": "Department of Biology, Boston University, Boston MA 02215, USA."
            },
            {
                "First Name": "Danielle",
                "Last Name": "LaMay",
                "Affiliation": "Department of Biology, Boston University, Boston MA 02215, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Jerry L",
                "Last Name": "Chen",
                "Affiliation": "Department of Biomedical Engineering, Boston University, Boston MA 02215, USA."
            }
        ],
        "Journal": "bioRxiv : the preprint server for biology",
        "PubDate": "2023"
    },
    {
        "PMID": "36823136",
        "Title": "Abstract representations emerge naturally in neural networks trained to perform multiple tasks.",
        "Abstract": "Humans and other animals demonstrate a remarkable ability to generalize knowledge across distinct contexts and objects during natural behavior. We posit that this ability to generalize arises from a specific representational geometry, that we call abstract and that is referred to as disentangled in machine learning. These abstract representations have been observed in recent neurophysiological studies. However, it is unknown how they emerge. Here, using feedforward neural networks, we demonstrate that the learning of multiple tasks causes abstract representations to emerge, using both supervised and reinforcement learning. We show that these abstract representations enable few-sample learning and reliable generalization on novel tasks. We conclude that abstract representations of sensory and cognitive variables may emerge from the multiple behaviors that animals exhibit in the natural world, and, as a consequence, could be pervasive in high-level brain regions. We also make several specific predictions about which variables will be represented abstractly.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Humans",
            "Neural Networks, Computer",
            "Brain"
        ],
        "Authors": [
            {
                "First Name": "W Jeffrey",
                "Last Name": "Johnston",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, USA. wjeffreyjohnston@gmail.com."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, USA. sf2237@columbia.edu."
            }
        ],
        "Journal": "Nature communications",
        "PubDate": "2023"
    },
    {
        "PMID": "36636347",
        "Title": "Face familiarity detection with complex synapses.",
        "Abstract": "Synaptic plasticity is a complex phenomenon involving multiple biochemical processes that operate on different timescales. Complexity can greatly increase memory capacity when the variables characterizing the synaptic dynamics have limited precision, as shown in simple memory retrieval problems involving random patterns. Here we turn to a real-world problem, face familiarity detection, and we show that synaptic complexity can be harnessed to store in memory a large number of faces that can be recognized at a later time. The number of recognizable faces grows almost linearly with the number of synapses and quadratically with the number of neurons. Complex synapses outperform simple ones characterized by a single variable, even when the total number of dynamical variables is matched. Complex and simple synapses have distinct signatures that are testable in experiments. Our results indicate that a system with complex synapses can be used in real-world tasks such as face familiarity detection.",
        "Keywords": [
            "Applied computing",
            "Artificial intelligence",
            "Neuroscience"
        ],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Li",
                "Last Name": "Ji-An",
                "Affiliation": "Zuckerman Institute, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Fabio",
                "Last Name": "Stefanini",
                "Affiliation": "Zuckerman Institute, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Marcus K",
                "Last Name": "Benna",
                "Affiliation": "Zuckerman Institute, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Zuckerman Institute, Columbia University, New York, NY 10027, USA."
            }
        ],
        "Journal": "iScience",
        "PubDate": "2023"
    },
    {
        "PMID": "36624277",
        "Title": "The geometry of cortical representations of touch in rodents.",
        "Abstract": "Neurons often encode highly heterogeneous non-linear functions of multiple task variables, a signature of a high-dimensional geometry. We studied the representational geometry in the somatosensory cortex of mice trained to report the curvature of objects touched by their whiskers. High-speed videos of the whiskers revealed that the task can be solved by linearly integrating multiple whisker contacts over time. However, the neural activity in somatosensory cortex reflects non-linear integration of spatio-temporal features of the sensory inputs. Although the responses at first appeared disorganized, we identified an interesting structure in the representational geometry: different whisker contacts are disentangled variables represented in approximately, but not fully, orthogonal subspaces of the neural activity space. This geometry allows linear readouts to perform a broad class of tasks of different complexities without compromising the ability to generalize to novel situations.",
        "Keywords": [],
        "MeSH terms": [
            "Mice",
            "Animals",
            "Touch",
            "Rodentia",
            "Touch Perception",
            "Neurons",
            "Somatosensory Cortex",
            "Vibrissae"
        ],
        "Authors": [
            {
                "First Name": "Ramon",
                "Last Name": "Nogueira",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, USA. rn2446@columbia.edu."
            },
            {
                "First Name": "Chris C",
                "Last Name": "Rodgers",
                "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Randy M",
                "Last Name": "Bruno",
                "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, USA. sf2237@columbia.edu."
            }
        ],
        "Journal": "Nature neuroscience",
        "PubDate": "2023"
    },
    {
        "PMID": "36332415",
        "Title": "The implications of categorical and category-free mixed selectivity on representational geometries.",
        "Abstract": "The firing rates of individual neurons displaying mixed selectivity are modulated by multiple task variables. When mixed selectivity is nonlinear, it confers an advantage by generating a high-dimensional neural representation that can be flexibly decoded by linear classifiers. Although the advantages of this coding scheme are well accepted, the means of designing an experiment and analyzing the data to test for and characterize mixed selectivity remain unclear. With the growing number of large datasets collected during complex tasks, the mixed selectivity is increasingly observed and is challenging to interpret correctly. We review recent approaches for analyzing and interpreting neural datasets\u00a0and clarify the theoretical implications of mixed selectivity in the variety of forms that have been reported in the literature. We also aim to provide a practical guide for determining whether a neural population has linear or nonlinear mixed selectivity\u00a0and whether this mixing leads to a categorical or category-free representation.",
        "Keywords": [],
        "MeSH terms": [
            "Models, Neurological",
            "Neurons"
        ],
        "Authors": [
            {
                "First Name": "Matthew T",
                "Last Name": "Kaufman",
                "Affiliation": "Department of Organismal Biology and Anatomy, Neuroscience Institute, University of Chicago, Chicago, IL, USA."
            },
            {
                "First Name": "Marcus K",
                "Last Name": "Benna",
                "Affiliation": "Department of Neurobiology, School of Biological Sciences, University of California, San Diego, CA, USA."
            },
            {
                "First Name": "Mattia",
                "Last Name": "Rigotti",
                "Affiliation": "IBM Research, Zurich, Switzerland."
            },
            {
                "First Name": "Fabio",
                "Last Name": "Stefanini",
                "Affiliation": "Mortimer B. Zuckerman Mind Brain Behavior Institute, Department of Neuroscience, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Mortimer B. Zuckerman Mind Brain Behavior Institute, Department of Neuroscience, Columbia University, New York, NY, USA. Electronic address: sf2237@columbia.edu."
            },
            {
                "First Name": "Anne K",
                "Last Name": "Churchland",
                "Affiliation": "David Geffen School of Medicine, University of California, Los Angeles, CA, USA. Electronic address: AChurchland@mednet.ucla.edu."
            }
        ],
        "Journal": "Current opinion in neurobiology",
        "PubDate": "2022"
    },
    {
        "PMID": "35590075",
        "Title": "Adolescent thalamic inhibition leads to long-lasting impairments in prefrontal cortex function.",
        "Abstract": "Impaired cortical maturation is a postulated mechanism in the etiology of neurodevelopmental disorders, including schizophrenia. In the sensory cortex, activity relayed by the thalamus during a postnatal sensitive period is essential for proper cortical maturation. Whether thalamic activity also shapes prefrontal cortical maturation is unknown. We show that inhibiting the mediodorsal and midline thalamus in mice during adolescence leads to a long-lasting decrease in thalamo-prefrontal projection density and reduced excitatory drive to prefrontal neurons. It also caused prefrontal-dependent cognitive deficits during adulthood associated with disrupted prefrontal cross-correlations and task outcome encoding. Thalamic inhibition during adulthood had no long-lasting consequences. Exciting the thalamus in adulthood during a cognitive task rescued prefrontal cross-correlations, task outcome encoding and cognitive deficits. These data point to adolescence as a sensitive window of thalamocortical circuit maturation. Furthermore, by supporting prefrontal network activity, boosting thalamic activity provides a potential therapeutic strategy for rescuing cognitive deficits in neurodevelopmental disorders.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Inhibition, Psychological",
            "Mice",
            "Neural Pathways",
            "Neurons",
            "Prefrontal Cortex",
            "Schizophrenia",
            "Thalamus"
        ],
        "Authors": [
            {
                "First Name": "Laura J",
                "Last Name": "Benoit",
                "Affiliation": "Graduate Program in Neurobiology and Behavior, Columbia University Irving Medical Center, New York, NY, USA."
            },
            {
                "First Name": "Emma S",
                "Last Name": "Holt",
                "Affiliation": "Department of Psychiatry, Columbia University Irving Medical Center, New York, NY, USA."
            },
            {
                "First Name": "Lorenzo",
                "Last Name": "Posani",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Alexander Z",
                "Last Name": "Harris",
                "Affiliation": "Department of Psychiatry, Columbia University Irving Medical Center, New York, NY, USA."
            },
            {
                "First Name": "Sarah",
                "Last Name": "Canetta",
                "Affiliation": "Department of Psychiatry, Columbia University Irving Medical Center, New York, NY, USA."
            },
            {
                "First Name": "Christoph",
                "Last Name": "Kellendonk",
                "Affiliation": "Department of Psychiatry, Columbia University Irving Medical Center, New York, NY, USA. ck491@cumc.columbia.edu."
            }
        ],
        "Journal": "Nature neuroscience",
        "PubDate": "2022"
    },
    {
        "PMID": "35447088",
        "Title": "Signatures of rapid plasticity in hippocampal CA1 representations during novel experiences.",
        "Abstract": "Neurons in the hippocampus exhibit a striking selectivity for specific combinations of sensory features, forming representations that are thought to subserve episodic memory. Even during completely novel experiences, hippocampal \"place cells\" are rapidly configured such that the population sparsely encodes visited locations, stabilizing within minutes of the first exposure to a new environment. What mechanisms enable this fast encoding of experience? Using virtual reality and neural population recordings in mice, we dissected the effects of novelty and experience on the dynamics of place field formation. During place field formation, many CA1 neurons immediately modulated the amplitude of their activity and shifted the location of their field, rapid changes in tuning predicted by behavioral timescale synaptic plasticity (BTSP). Signatures of BTSP were particularly enriched during the exploration of a novel context and decayed with experience. Our data suggest that novelty modulates the effective learning rate in CA1, favoring rapid mechanisms of field formation to encode a new experience.",
        "Keywords": [
            "BTSP",
            "Hippocampus",
            "calcium imaging",
            "learning",
            "memory",
            "novelty",
            "place cell",
            "plasticity"
        ],
        "MeSH terms": [
            "Animals",
            "CA1 Region, Hippocampal",
            "Hippocampus",
            "Learning",
            "Mice",
            "Neuronal Plasticity",
            "Neurons",
            "Place Cells"
        ],
        "Authors": [
            {
                "First Name": "James B",
                "Last Name": "Priestley",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Doctoral Program in Neurobiology and Behavior, Columbia University, New York, NY 10027, USA; Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA. Electronic address: jbp2150@columbia.edu."
            },
            {
                "First Name": "John C",
                "Last Name": "Bowler",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Doctoral Program in Neurobiology and Behavior, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Sebi V",
                "Last Name": "Rolotti",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Doctoral Program in Neurobiology and Behavior, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA; Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Attila",
                "Last Name": "Losonczy",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA. Electronic address: al2856@columbia.edu."
            }
        ],
        "Journal": "Neuron",
        "PubDate": "2022"
    },
    {
        "PMID": "34916282",
        "Title": "Place cells may simply be memory cells: Memory compression leads to spatial tuning and history dependence.",
        "Abstract": "The observation of place cells has suggested that the hippocampus plays a special role in encoding spatial information. However, place cell responses are modulated by several nonspatial variables and reported to be rather unstable. Here, we propose a memory model of the hippocampus that provides an interpretation of place cells consistent with these observations. We hypothesize that the hippocampus is a memory device that takes advantage of the correlations between sensory experiences to generate compressed representations of the episodes that are stored in memory. A simple neural network model that can efficiently compress information naturally produces place cells that are similar to those observed in experiments. It predicts that the activity of these cells is variable and that the fluctuations of the place fields encode information about the recent history of sensory experiences. Place cells may simply be a consequence of a memory compression process implemented in the hippocampus.",
        "Keywords": [
            "compression",
            "hippocampus",
            "memory",
            "place cells",
            "sparse autoencoders"
        ],
        "MeSH terms": [
            "Animals",
            "Hippocampus",
            "Models, Neurological",
            "Nerve Net",
            "Spatial Memory",
            "Spatial Navigation"
        ],
        "Authors": [
            {
                "First Name": "Marcus K",
                "Last Name": "Benna",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY 10027; mbenna@ucsd.edu sf2237@columbia.edu."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, NY 10027; mbenna@ucsd.edu sf2237@columbia.edu."
            }
        ],
        "Journal": "Proceedings of the National Academy of Sciences of the United States of America",
        "PubDate": "2021"
    },
    {
        "PMID": "34133944",
        "Title": "Sensorimotor strategies and neuronal representations for shape discrimination.",
        "Abstract": "Humans and other animals can identify objects by active touch, requiring the coordination of exploratory motion and tactile sensation. Both the motor strategies and neural representations employed could depend on the subject's goals. We developed a shape discrimination task that challenged head-fixed mice to discriminate concave from convex shapes. Behavioral decoding revealed that mice did this by comparing contacts across whiskers. In contrast, a separate group of mice performing a shape detection task simply summed up contacts over whiskers. We recorded populations of neurons in the barrel cortex, which processes whisker input, and found that individual neurons across the cortical layers encoded touch, whisker motion, and task-related signals. Sensory representations were task-specific: during shape discrimination, but not detection, neurons responded most to behaviorally relevant whiskers, overriding somatotopy. Thus, sensory cortex employs task-specific representations compatible with behaviorally relevant computations.",
        "Keywords": [
            "active sensing",
            "barrel cortex",
            "behavior",
            "behavioral decoding",
            "electrophysiology",
            "encoding models",
            "generalized linear model",
            "modeling",
            "shape discrimination",
            "somatosensory cortex",
            "whiskers"
        ],
        "MeSH terms": [
            "Animals",
            "Discrimination Learning",
            "Form Perception",
            "Mice",
            "Neurons",
            "Somatosensory Cortex",
            "Touch Perception",
            "Vibrissae"
        ],
        "Authors": [
            {
                "First Name": "Chris C",
                "Last Name": "Rodgers",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA; Kavli Institute for Brain Science, Columbia University, New York, NY 10027, USA. Electronic address: xrodgers@gmail.com."
            },
            {
                "First Name": "Ramon",
                "Last Name": "Nogueira",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA; Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "B Christina",
                "Last Name": "Pil",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA; Kavli Institute for Brain Science, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Esther A",
                "Last Name": "Greeman",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA; Kavli Institute for Brain Science, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Jung M",
                "Last Name": "Park",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA; Kavli Institute for Brain Science, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Y Kate",
                "Last Name": "Hong",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA; Kavli Institute for Brain Science, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA; Kavli Institute for Brain Science, Columbia University, New York, NY 10027, USA; Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Randy M",
                "Last Name": "Bruno",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA; Kavli Institute for Brain Science, Columbia University, New York, NY 10027, USA. Electronic address: randybruno@columbia.edu."
            }
        ],
        "Journal": "Neuron",
        "PubDate": "2021"
    },
    {
        "PMID": "33420715",
        "Title": "Perceiving ensemble statistics of novel image sets.",
        "Abstract": "Perception, representation, and memory of ensemble statistics has attracted growing interest. Studies found that, at different abstraction levels, the brain represents similar items as unified percepts. We found that global ensemble perception is automatic and unconscious, affecting later perceptual judgments regarding individual member items. Implicit effects of set mean and range for low-level feature ensembles (size, orientation, brightness) were replicated for high-level category objects. This similarity suggests that analogous mechanisms underlie these extreme levels of abstraction. Here, we bridge the span between visual features and semantic object categories using the identical implicit perception experimental paradigm for intermediate novel visual-shape categories, constructing ensemble exemplars by introducing systematic variations of a central category base or ancestor. In five experiments, with different item variability, we test automatic representation of ensemble category characteristics and its effect on a subsequent memory task. Results show that observer representation of ensembles includes the group's central shape, category ancestor (progenitor), or group mean. Observers also easily reject memory of shapes belonging to different categories, i.e. originating from different ancestors. We conclude that complex categories, like simple visual form ensembles, are represented in terms of statistics including a central object, as well as category boundaries. We refer to the model proposed by Benna and Fusi (bioRxiv 624239, 2019) that memory representation is compressed when related elements are represented by identifying their ancestor and each one's difference from it. We suggest that ensemble mean perception, like category prototype extraction, might reflect employment at different representation levels of an essential, general representation mechanism.",
        "Keywords": [
            "Categorization",
            "Ensemble Perception",
            "Implicit/explicit memory",
            "Visual perception"
        ],
        "MeSH terms": [
            "Brain",
            "Brain Mapping",
            "Concept Formation",
            "Humans",
            "Judgment",
            "Semantics",
            "Visual Perception"
        ],
        "Authors": [
            {
                "First Name": "Noam",
                "Last Name": "Khayat",
                "Affiliation": "ELSC Edmond & Lily Safra Center for Brain Research and Silberman Life Sciences Institute, Hebrew University, Jerusalem, Israel."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Mortimer B. Zuckerman Mind Brain and Behavior Institute and Department of Neuroscience, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Shaul",
                "Last Name": "Hochstein",
                "Affiliation": "ELSC Edmond & Lily Safra Center for Brain Research and Silberman Life Sciences Institute, Hebrew University, Jerusalem, Israel. shaul.hochstein@gmail.com."
            }
        ],
        "Journal": "Attention, perception & psychophysics",
        "PubDate": "2021"
    },
    {
        "PMID": "33077947",
        "Title": "Coding of social novelty in the hippocampal CA2 region and its disruption and rescue in a 22q11.2 microdeletion mouse model.",
        "Abstract": "The hippocampal CA2 region is essential for social memory. To determine whether CA2 activity encodes social interactions, we recorded extracellularly from CA2 pyramidal neurons (PNs) in male mice during social behavior. Although CA2 neuronal firing showed only weak spatial selectivity, it accurately encoded contextual changes and distinguished between a novel and a familiar mouse. In the Df(16)A",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Animals",
            "CA2 Region, Hippocampal",
            "Chromosome Deletion",
            "Chromosomes, Human, Pair 22",
            "Disease Models, Animal",
            "Exploratory Behavior",
            "Male",
            "Mice, Inbred C57BL",
            "Mice, Transgenic",
            "Pyramidal Cells",
            "Social Behavior",
            "Social Interaction",
            "Spatial Processing"
        ],
        "Authors": [
            {
                "First Name": "Macayla L",
                "Last Name": "Donegan",
                "Affiliation": "Department of Neuroscience, Zuckerman and Kavli Institutes, Vagelos College of Physicians and Surgeons, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Fabio",
                "Last Name": "Stefanini",
                "Affiliation": "Department of Neuroscience, Zuckerman and Kavli Institutes, Vagelos College of Physicians and Surgeons, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Torcato",
                "Last Name": "Meira",
                "Affiliation": "Department of Neuroscience, Zuckerman and Kavli Institutes, Vagelos College of Physicians and Surgeons, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Joshua A",
                "Last Name": "Gordon",
                "Affiliation": "National Institute of Mental Health, NIH, Bethesda, MD, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Department of Neuroscience, Zuckerman and Kavli Institutes, Vagelos College of Physicians and Surgeons, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Steven A",
                "Last Name": "Siegelbaum",
                "Affiliation": "Department of Neuroscience, Zuckerman and Kavli Institutes, Vagelos College of Physicians and Surgeons, Columbia University, New York, NY, USA. sas8@cumc.columbia.edu."
            }
        ],
        "Journal": "Nature neuroscience",
        "PubDate": "2020"
    },
    {
        "PMID": "33058757",
        "Title": "The Geometry of Abstraction in the Hippocampus and Prefrontal Cortex.",
        "Abstract": "The curse of dimensionality plagues models of reinforcement learning and decision making. The process of abstraction solves this by constructing variables describing features shared by different instances, reducing dimensionality and enabling generalization in novel situations. Here, we characterized neural representations in monkeys performing a task described by different hidden and explicit variables. Abstraction was defined operationally using the generalization performance of neural decoders across task conditions not used for training, which requires a particular geometry of neural representations. Neural ensembles in prefrontal cortex, hippocampus, and simulated neural networks simultaneously represented multiple variables in a geometry reflecting abstraction but that still allowed a linear classifier to decode a large number of other variables (high shattering dimensionality). Furthermore, this geometry changed in relation to task events and performance. These findings elucidate how the brain and artificial systems represent variables in an abstract format while preserving the advantages conferred by high shattering dimensionality.",
        "Keywords": [
            "abstraction",
            "anterior cingulate cortex",
            "artificial neural networks",
            "dimensionality",
            "disentangled representations",
            "factorized representations",
            "hippocampus",
            "mixed selectivity",
            "prefrontal cortex",
            "representational geometry"
        ],
        "MeSH terms": [
            "Animals",
            "Behavior, Animal",
            "Brain Mapping",
            "Computer Simulation",
            "Hippocampus",
            "Learning",
            "Macaca mulatta",
            "Male",
            "Models, Neurological",
            "Neural Networks, Computer",
            "Neurons",
            "Prefrontal Cortex",
            "Reinforcement, Psychology",
            "Task Performance and Analysis"
        ],
        "Authors": [
            {
                "First Name": "Silvia",
                "Last Name": "Bernardi",
                "Affiliation": "Department of Psychiatry, Columbia University, New York, NY, USA; Research Foundation for Mental Hygiene, Menands, NY, USA; Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA; New York State Psychiatric Institute, New York, NY, USA."
            },
            {
                "First Name": "Marcus K",
                "Last Name": "Benna",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY, USA; Center for Theoretical Neuroscience, Columbia University, New York, NY, USA; Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA; Neurobiology Section, Division of Biological Sciences, University of California, San Diego, La Jolla, CA, USA."
            },
            {
                "First Name": "Mattia",
                "Last Name": "Rigotti",
                "Affiliation": "IBM Research AI, Yorktown Heights, NY, USA."
            },
            {
                "First Name": "J\u00e9r\u00f4me",
                "Last Name": "Munuera",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY, USA; Center for Theoretical Neuroscience, Columbia University, New York, NY, USA; Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA; Kavli Institute for Brain Sciences, Columbia University, New York, NY, USA. Electronic address: sf2237@columbia.edu."
            },
            {
                "First Name": "C Daniel",
                "Last Name": "Salzman",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY, USA; Department of Psychiatry, Columbia University, New York, NY, USA; Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA; Kavli Institute for Brain Sciences, Columbia University, New York, NY, USA; New York State Psychiatric Institute, New York, NY, USA. Electronic address: cds2005@columbia.edu."
            }
        ],
        "Journal": "Cell",
        "PubDate": "2020"
    },
    {
        "PMID": "32974699",
        "Title": "Surgical Outcomes of Mastectomy with Immediate Autologous Reconstruction Followed by Radiation.",
        "Abstract": "Timing of autologous reconstruction relative to postmastectomy radiation therapy (PMRT) is debated. Benefits of immediate reconstruction must be weighed against a possibly heightened risk of complications from flap irradiation. We reviewed flap outcomes after single operation plus PMRT in a large institutional cohort.",
        "Keywords": [],
        "MeSH terms": [
            "Breast Neoplasms",
            "Female",
            "Follow-Up Studies",
            "Humans",
            "Mammaplasty",
            "Mastectomy",
            "Postoperative Complications",
            "Radiotherapy, Adjuvant",
            "Retrospective Studies",
            "Treatment Outcome"
        ],
        "Authors": [
            {
                "First Name": "Danielle R",
                "Last Name": "Heller",
                "Affiliation": "Department of Surgery, Yale University School of Medicine, New Haven, CT, USA."
            },
            {
                "First Name": "Haoran",
                "Last Name": "Zhuo",
                "Affiliation": "School of Public Health, Yale University School of Medicine, New Haven, CT, USA."
            },
            {
                "First Name": "Yawei",
                "Last Name": "Zhang",
                "Affiliation": "School of Public Health, Yale University School of Medicine, New Haven, CT, USA."
            },
            {
                "First Name": "Nisha",
                "Last Name": "Parikh",
                "Affiliation": "Department of Therapeutic Radiology, Yale University School of Medicine, New Haven, CT, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Department of Surgery, Yale University School of Medicine, New Haven, CT, USA."
            },
            {
                "First Name": "Michael",
                "Last Name": "Alperovich",
                "Affiliation": "Division of Plastic and Reconstructive Surgery, Yale University School of Medicine, New Haven, CT, USA."
            },
            {
                "First Name": "Donald R",
                "Last Name": "Lannin",
                "Affiliation": "The Breast Center, Department of Surgery, Yale University School of Medicine, New Haven, CT, USA."
            },
            {
                "First Name": "Susan A",
                "Last Name": "Higgins",
                "Affiliation": "Department of Therapeutic Radiology, Yale University School of Medicine, New Haven, CT, USA."
            },
            {
                "First Name": "Tomer",
                "Last Name": "Avraham",
                "Affiliation": "Division of Plastic and Reconstructive Surgery, Yale University School of Medicine, New Haven, CT, USA."
            },
            {
                "First Name": "Brigid K",
                "Last Name": "Killelea",
                "Affiliation": "The Breast Center, Department of Surgery, Yale University School of Medicine, New Haven, CT, USA. Brigid.killelea@yale.edu."
            }
        ],
        "Journal": "Annals of surgical oncology",
        "PubDate": "2021"
    },
    {
        "PMID": "32859756",
        "Title": "Low-dimensional dynamics for working memory and time encoding.",
        "Abstract": "Our decisions often depend on multiple sensory experiences separated by time delays. The brain can remember these experiences and, simultaneously, estimate the timing between events. To understand the mechanisms underlying working memory and time encoding, we analyze neural activity recorded during delays in four experiments on nonhuman primates. To disambiguate potential mechanisms, we propose two analyses, namely, decoding the passage of time from neural data and computing the cumulative dimensionality of the neural trajectory over time. Time can be decoded with high precision in tasks where timing information is relevant and with lower precision when irrelevant for performing the task. Neural trajectories are always observed to be low-dimensional. In addition, our results further constrain the mechanisms underlying time encoding as we find that the linear \"ramping\" component of each neuron's firing rate strongly contributes to the slow timescale variations that make decoding time possible. These constraints rule out working memory models that rely on constant, sustained activity and neural networks with high-dimensional trajectories, like reservoir networks. Instead, recurrent networks trained with backpropagation capture the time-encoding properties and the dimensionality observed in the data.",
        "Keywords": [
            "neural dynamics",
            "recurrent networks",
            "reservoir computing",
            "time decoding",
            "working memory"
        ],
        "MeSH terms": [
            "Animals",
            "Brain",
            "Brain Mapping",
            "Memory, Short-Term",
            "Nerve Net",
            "Neural Networks, Computer",
            "Neurons",
            "Primates"
        ],
        "Authors": [
            {
                "First Name": "Christopher J",
                "Last Name": "Cueva",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027; ccueva@gmail.com ranulfo.romo@gmail.com sf2237@columbia.edu."
            },
            {
                "First Name": "Alex",
                "Last Name": "Saez",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027."
            },
            {
                "First Name": "Encarni",
                "Last Name": "Marcos",
                "Affiliation": "Instituto de Neurociencias de Alicante, Consejo Superior de Investigaciones Cient\u00edficas-Universidad Miguel Hern\u00e1ndez de Elche, San Juan de Alicante 03550, Spain."
            },
            {
                "First Name": "Aldo",
                "Last Name": "Genovesio",
                "Affiliation": "Department of Physiology and Pharmacology, Sapienza University of Rome, Rome 00185, Italy."
            },
            {
                "First Name": "Mehrdad",
                "Last Name": "Jazayeri",
                "Affiliation": "McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA 02139."
            },
            {
                "First Name": "Ranulfo",
                "Last Name": "Romo",
                "Affiliation": "Instituto de Fisiolg\u00eda Celular-Neurociencias, Universidad Nacional Aut\u00f3noma de M\u00e9xico, 04510 Mexico City, Mexico; ccueva@gmail.com ranulfo.romo@gmail.com sf2237@columbia.edu."
            },
            {
                "First Name": "C Daniel",
                "Last Name": "Salzman",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027."
            },
            {
                "First Name": "Michael N",
                "Last Name": "Shadlen",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027; ccueva@gmail.com ranulfo.romo@gmail.com sf2237@columbia.edu."
            }
        ],
        "Journal": "Proceedings of the National Academy of Sciences of the United States of America",
        "PubDate": "2020"
    },
    {
        "PMID": "32586990",
        "Title": "Flexible recruitment of memory-based choice representations by the human medial frontal cortex.",
        "Abstract": "Decision-making in complex environments relies on flexibly using prior experience. This process depends on the medial frontal cortex (MFC) and the medial temporal lobe, but it remains unknown how these structures implement selective memory retrieval. We recorded single neurons in the MFC, amygdala, and hippocampus while human subjects switched between making recognition memory-based and categorization-based decisions. The MFC rapidly implemented changing task demands by using different subspaces of neural activity and by representing the currently relevant task goal. Choices requiring memory retrieval selectively engaged phase-locking of MFC neurons to amygdala and hippocampus field potentials, thereby enabling the routing of memories. These findings reveal a mechanism for flexibly and selectively engaging memory retrieval and show that memory-based choices are preferentially represented in the frontal cortex when required.",
        "Keywords": [],
        "MeSH terms": [
            "Adult",
            "Choice Behavior",
            "Humans",
            "Magnetic Resonance Imaging",
            "Neurons",
            "Prefrontal Cortex",
            "Recognition, Psychology"
        ],
        "Authors": [
            {
                "First Name": "Juri",
                "Last Name": "Minxha",
                "Affiliation": "Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, CA, USA."
            },
            {
                "First Name": "Ralph",
                "Last Name": "Adolphs",
                "Affiliation": "Computation and Neural Systems Program, Division of Biology and Biological Engineering, California Institute of Technology, Pasadena, CA, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Adam N",
                "Last Name": "Mamelak",
                "Affiliation": "Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, CA, USA."
            },
            {
                "First Name": "Ueli",
                "Last Name": "Rutishauser",
                "Affiliation": "Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, CA, USA. ueli.rutishauser@csmc.edu."
            }
        ],
        "Journal": "Science (New York, N.Y.)",
        "PubDate": "2020"
    },
    {
        "PMID": "32521223",
        "Title": "A Distributed Neural Code in the Dentate Gyrus and in CA1.",
        "Abstract": "Neurons are often considered specialized functional units that encode a single variable. However, many neurons are observed to respond to a mix of disparate sensory, cognitive, and behavioral variables. For such representations, information is distributed across multiple neurons. Here we find this distributed code in the dentate gyrus and CA1 subregions of the hippocampus. Using calcium imaging in freely moving mice, we decoded an animal's position, direction of motion, and speed from the activity of hundreds of cells. The response properties of individual neurons were only partially predictive of their importance for encoding position. Non-place cells encoded position and contributed to position encoding when combined with other cells. Indeed, disrupting the correlations between neural activities decreased decoding performance, mostly in CA1. Our analysis indicates that population methods rather than classical analyses based on single-cell response properties may more accurately characterize the neural code in the hippocampus.",
        "Keywords": [
            "calcium imaging",
            "correlated activity",
            "decoding",
            "dentate gyrus",
            "distributed representations",
            "hippocampus",
            "mixed selectivity",
            "place cells",
            "population coding"
        ],
        "MeSH terms": [
            "Action Potentials",
            "Animals",
            "CA1 Region, Hippocampal",
            "Calcium",
            "Dentate Gyrus",
            "Mice",
            "Neurons",
            "Spatial Behavior"
        ],
        "Authors": [
            {
                "First Name": "Fabio",
                "Last Name": "Stefanini",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons, Columbia University, New York, NY, USA; Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Lyudmila",
                "Last Name": "Kushnir",
                "Affiliation": "GNT-LNC, D\u00e9partment d'\u00c9tudes Cognitives, \u00c9cole Normale Sup\u00e9rieure, INSERM, PSL Research University, 75005 Paris, France."
            },
            {
                "First Name": "Jessica C",
                "Last Name": "Jimenez",
                "Affiliation": "Departments of Neuroscience, Psychiatry, & Pharmacology, Columbia University, New York, NY, USA; Division of Integrative Neuroscience, Department of Psychiatry, New York State Psychiatric Institute, New York, NY, USA."
            },
            {
                "First Name": "Joshua H",
                "Last Name": "Jennings",
                "Affiliation": "Department of Bioengineering, Stanford University, Stanford, CA 94305, USA."
            },
            {
                "First Name": "Nicholas I",
                "Last Name": "Woods",
                "Affiliation": "Neuroscience Graduate Program, University of California, San Francisco, San Francisco, CA, USA; Medical Scientist Training Program, University of California, San Francisco, San Francisco, CA, USA."
            },
            {
                "First Name": "Garret D",
                "Last Name": "Stuber",
                "Affiliation": "Center for the Neurobiology of Addiction, Pain, and Emotion, Department of Anesthesiology and Pain Medicine, Department of Pharmacology, University of Washington, Seattle, WA 98195, USA."
            },
            {
                "First Name": "Mazen A",
                "Last Name": "Kheirbek",
                "Affiliation": "Neuroscience Graduate Program, University of California, San Francisco, San Francisco, CA, USA; Department of Psychiatry, University of California, San Francisco, San Francisco, CA, USA; Weill Institute for Neurosciences, University of California, San Francisco, San Francisco, CA, USA; Kavli Institute for Fundamental Neuroscience, University of California, San Francisco, San Francisco, CA, USA. Electronic address: mazen.kheirbek@ucsf.edu."
            },
            {
                "First Name": "Ren\u00e9",
                "Last Name": "Hen",
                "Affiliation": "Departments of Neuroscience, Psychiatry, & Pharmacology, Columbia University, New York, NY, USA; Division of Integrative Neuroscience, Department of Psychiatry, New York State Psychiatric Institute, New York, NY, USA; Kavli Institute for Brain Sciences, Columbia University, New York, NY, USA. Electronic address: rh95@cumc.columbia.edu."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons, Columbia University, New York, NY, USA; Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA; Department of Bioengineering, Stanford University, Stanford, CA 94305, USA; Kavli Institute for Brain Sciences, Columbia University, New York, NY, USA. Electronic address: sf2237@columbia.edu."
            }
        ],
        "Journal": "Neuron",
        "PubDate": "2020"
    },
    {
        "PMID": "32392472",
        "Title": "Hippocampal Network Reorganization Underlies the Formation of a Temporal Association Memory.",
        "Abstract": "Episodic memory requires linking events in time, a function dependent on the hippocampus. In \"trace\" fear conditioning, animals learn to associate a neutral cue with an aversive stimulus despite their separation in time by a delay period on the order of tens of seconds. But how this temporal association forms remains unclear. Here we use two-photon calcium imaging of neural population dynamics throughout the course of learning and show that, in contrast to previous theories, hippocampal CA1 does not generate persistent activity to bridge the delay. Instead, learning is concomitant with broad changes in the active neural population. Although neural responses were stochastic in time, cue identity could be read out from population activity over longer timescales after learning. These results question the ubiquity of seconds-long neural sequences during temporal association learning and suggest that trace fear conditioning relies on mechanisms that differ from persistent activity accounts of working memory.",
        "Keywords": [
            "calcium imaging",
            "hippocampus",
            "learning",
            "memory",
            "population coding",
            "trace fear conditioning"
        ],
        "MeSH terms": [
            "Animals",
            "Association Learning",
            "Behavior, Animal",
            "CA1 Region, Hippocampal",
            "Conditioning, Operant",
            "Cues",
            "Fear",
            "Hippocampus",
            "Image Processing, Computer-Assisted",
            "Memory, Episodic",
            "Memory, Short-Term",
            "Mice",
            "Mice, Inbred C57BL",
            "Nerve Net",
            "Neurons",
            "Optogenetics"
        ],
        "Authors": [
            {
                "First Name": "Mohsin S",
                "Last Name": "Ahmed",
                "Affiliation": "Department of Psychiatry, Columbia University, New York, NY 10032, USA; Department of Neuroscience, Columbia University, New York, NY 10027, USA; Division of Molecular Therapeutics, New York State Psychiatric Institute, New York, NY 10032, USA."
            },
            {
                "First Name": "James B",
                "Last Name": "Priestley",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Doctoral Program in Neurobiology and Behavior, Columbia University, New York, NY 10027, USA; Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Angel",
                "Last Name": "Castro",
                "Affiliation": "Department of Psychiatry, Columbia University, New York, NY 10032, USA; Department of Neuroscience, Columbia University, New York, NY 10027, USA; Division of Molecular Therapeutics, New York State Psychiatric Institute, New York, NY 10032, USA."
            },
            {
                "First Name": "Fabio",
                "Last Name": "Stefanini",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Ana Sofia",
                "Last Name": "Solis Canales",
                "Affiliation": "Division of Molecular Therapeutics, New York State Psychiatric Institute, New York, NY 10032, USA."
            },
            {
                "First Name": "Elizabeth M",
                "Last Name": "Balough",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Doctoral Program in Neurobiology and Behavior, Columbia University, New York, NY 10027, USA."
            },
            {
                "First Name": "Erin",
                "Last Name": "Lavoie",
                "Affiliation": "Division of Molecular Therapeutics, New York State Psychiatric Institute, New York, NY 10032, USA."
            },
            {
                "First Name": "Luca",
                "Last Name": "Mazzucato",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA; Departments of Mathematics and Biology, University of Oregon, Eugene, OR 97403, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Center for Theoretical Neuroscience, Columbia University, New York, NY 10027, USA; Kavli Institute for Brain Sciences, Columbia University, New York, NY 10027, USA; Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA. Electronic address: sf2237@columbia.edu."
            },
            {
                "First Name": "Attila",
                "Last Name": "Losonczy",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10027, USA; Kavli Institute for Brain Sciences, Columbia University, New York, NY 10027, USA; Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA. Electronic address: al2856@columbia.edu."
            }
        ],
        "Journal": "Neuron",
        "PubDate": "2020"
    },
    {
        "PMID": "32346488",
        "Title": "Does walking the day of total hip arthroplasty speed up functional independence? A non-randomized controlled study.",
        "Abstract": "Few data address modalities for speeding up functional independence in subjects included in a fast-track approach after total hip arthroplasty (THA). The study aim was to assess short-term effects of mobilization and walking the day of THA (WDS) on independence, pain, function and quality of life.",
        "Keywords": [
            "Arthroplasty replacement hip",
            "Early ambulation",
            "Functional independence",
            "Rehabilitation"
        ],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Federico",
                "Last Name": "Temporiti",
                "Affiliation": "1Physiotherapy Unit, Humanitas Clinical and Research Center, Via Manzoni 56 - Rozzano, Milan, Italy."
            },
            {
                "First Name": "Isabella",
                "Last Name": "Draghici",
                "Affiliation": "3Hip and Knee Orthopaedic Surgery Department, Humanitas Clinical and Research Center, Rozzano, Milan, Italy."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "1Physiotherapy Unit, Humanitas Clinical and Research Center, Via Manzoni 56 - Rozzano, Milan, Italy."
            },
            {
                "First Name": "Francesco",
                "Last Name": "Traverso",
                "Affiliation": "3Hip and Knee Orthopaedic Surgery Department, Humanitas Clinical and Research Center, Rozzano, Milan, Italy."
            },
            {
                "First Name": "Riccardo",
                "Last Name": "Ruggeri",
                "Affiliation": "3Hip and Knee Orthopaedic Surgery Department, Humanitas Clinical and Research Center, Rozzano, Milan, Italy."
            },
            {
                "First Name": "Guido",
                "Last Name": "Grappiolo",
                "Affiliation": "3Hip and Knee Orthopaedic Surgery Department, Humanitas Clinical and Research Center, Rozzano, Milan, Italy."
            },
            {
                "First Name": "Roberto",
                "Last Name": "Gatti",
                "Affiliation": "1Physiotherapy Unit, Humanitas Clinical and Research Center, Via Manzoni 56 - Rozzano, Milan, Italy."
            }
        ],
        "Journal": "Archives of physiotherapy",
        "PubDate": "2020"
    },
    {
        "PMID": "31873285",
        "Title": "Context-dependent representations of objects and space in the primate hippocampus during virtual navigation.",
        "Abstract": "The hippocampus is implicated in associative memory and spatial navigation. To investigate how these functions are mixed in the hippocampus, we recorded from single hippocampal neurons in macaque monkeys navigating a virtual maze during a foraging task and a context-object associative memory task. During both tasks, single neurons encoded information about spatial position; a linear classifier also decoded position. However, the population code for space did not generalize across tasks, particularly where stimuli relevant to the associative memory task appeared. Single-neuron and population-level analyses revealed that cross-task changes were due to selectivity for nonspatial features of the associative memory task when they were visually available (perceptual coding) and following their disappearance (mnemonic coding). Our results show that neurons in the primate hippocampus nonlinearly mix information about space and nonspatial elements of the environment in a task-dependent manner; this efficient code flexibly represents unique perceptual experiences and correspondent memories.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Hippocampus",
            "Macaca mulatta",
            "Male",
            "Memory",
            "Neurons",
            "Space Perception",
            "Spatial Navigation"
        ],
        "Authors": [
            {
                "First Name": "Roberto A",
                "Last Name": "Gulli",
                "Affiliation": "Integrated Program in Neuroscience, McGill University, Montr\u00e9al, Quebec, Canada. roberto.gulli@mail.mcgill.ca."
            },
            {
                "First Name": "Lyndon R",
                "Last Name": "Duong",
                "Affiliation": "Robarts Research Institute, Western University, London, Ontario, Canada."
            },
            {
                "First Name": "Benjamin W",
                "Last Name": "Corrigan",
                "Affiliation": "Integrated Program in Neuroscience, McGill University, Montr\u00e9al, Quebec, Canada."
            },
            {
                "First Name": "Guillaume",
                "Last Name": "Doucet",
                "Affiliation": "Robarts Research Institute, Western University, London, Ontario, Canada."
            },
            {
                "First Name": "Sylvain",
                "Last Name": "Williams",
                "Affiliation": "Department of Psychiatry, Douglas Research Center, McGill University, Montr\u00e9al, Quebec, Canada."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA."
            },
            {
                "First Name": "Julio C",
                "Last Name": "Martinez-Trujillo",
                "Affiliation": "Robarts Research Institute, Western University, London, Ontario, Canada."
            }
        ],
        "Journal": "Nature neuroscience",
        "PubDate": "2020"
    },
    {
        "PMID": "30931937",
        "Title": "Deviation from the matching law reflects an optimal strategy involving learning over multiple timescales.",
        "Abstract": "Behavior deviating from our normative expectations often appears irrational. For example, even though behavior following the so-called matching law can maximize reward in a stationary foraging task, actual behavior commonly deviates from matching. Such behavioral deviations are interpreted as a failure of the subject; however, here we instead suggest that they reflect an adaptive strategy, suitable for uncertain, non-stationary environments. To prove it, we analyzed the behavior of primates that perform a dynamic foraging task. In such nonstationary environment, learning on both fast and slow timescales is beneficial: fast learning allows the animal to react to sudden changes, at the price of large fluctuations (variance) in the estimates of task relevant variables. Slow learning reduces the fluctuations but costs a bias that causes systematic behavioral deviations. Our behavioral analysis shows that the animals solved this bias-variance tradeoff by combining learning on both fast and slow timescales, suggesting that learning on multiple timescales can be a biologically plausible mechanism for optimizing decisions under uncertainty.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Appetitive Behavior",
            "Behavior, Animal",
            "Learning",
            "Macaca mulatta",
            "Male",
            "Models, Theoretical",
            "Reward",
            "Time Factors",
            "Uncertainty"
        ],
        "Authors": [
            {
                "First Name": "Kiyohito",
                "Last Name": "Iigaya",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons, Columbia University, New York, NY, 10032, USA. kiigaya@gatsby.ucl.ac.uk."
            },
            {
                "First Name": "Yashar",
                "Last Name": "Ahmadian",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons, Columbia University, New York, NY, 10032, USA."
            },
            {
                "First Name": "Leo P",
                "Last Name": "Sugrue",
                "Affiliation": "Howard Hughes Medical Institute and Department of Neurobiology, Stanford University School of Medicine, Stanford, CA, 94305, USA."
            },
            {
                "First Name": "Greg S",
                "Last Name": "Corrado",
                "Affiliation": "Howard Hughes Medical Institute and Department of Neurobiology, Stanford University School of Medicine, Stanford, CA, 94305, USA."
            },
            {
                "First Name": "Yonatan",
                "Last Name": "Loewenstein",
                "Affiliation": "Department of Neurobiology, Edmond and Lily Safra Center for Brain Sciences, The Hebrew University of Jerusalem, 91904, Jerusalem, Israel."
            },
            {
                "First Name": "William T",
                "Last Name": "Newsome",
                "Affiliation": "Howard Hughes Medical Institute and Department of Neurobiology, Stanford University School of Medicine, Stanford, CA, 94305, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons, Columbia University, New York, NY, 10032, USA. sf2237@columbia.edu."
            }
        ],
        "Journal": "Nature communications",
        "PubDate": "2019"
    },
    {
        "PMID": "30249794",
        "Title": "Neural Classifiers with Limited Connectivity and Recurrent Readouts.",
        "Abstract": "For many neural network models in which neurons are trained to classify inputs like perceptrons, the number of inputs that can be classified is limited by the connectivity of each neuron, even when the total number of neurons is very large. This poses the problem of how the biological brain can take advantage of its huge number of neurons given that the connectivity is sparse. One solution is to combine multiple perceptrons together, as in committee machines. The number of classifiable random patterns would then grow linearly with the number of perceptrons, even when each perceptron has limited connectivity. However, the problem is moved to the downstream readout neurons, which would need a number of connections as large as the number of perceptrons. Here we propose a different approach in which the readout is implemented by connecting multiple perceptrons in a recurrent attractor neural network. We prove analytically that the number of classifiable random patterns can grow unboundedly with the number of perceptrons, even when the connectivity of each perceptron remains finite. Most importantly, both the recurrent connectivity and the connectivity of downstream readouts also remain finite. Our study shows that feedforward neural classifiers with numerous long-range afferent connections can be replaced by recurrent networks with sparse long-range connectivity without sacrificing the classification performance. Our strategy could be used to design more general scalable network architectures with limited connectivity, which resemble more closely the brain neural circuits that are dominated by recurrent connectivity.",
        "Keywords": [
            "attractor networks",
            "classifier",
            "committee machines",
            "perceptron",
            "sparse connectivity"
        ],
        "MeSH terms": [
            "Action Potentials",
            "Animals",
            "Brain",
            "Models, Neurological",
            "Neural Networks, Computer",
            "Neurons"
        ],
        "Authors": [
            {
                "First Name": "Lyudmila",
                "Last Name": "Kushnir",
                "Affiliation": "LNC2, Departement d'Etudes Cognitives, Ecole Normale Superieure, Institut National de la Sant\u00e9 et de la Recherche M\u00e9dicale, PSL Research University, 75005 Paris, France."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons, sf2237@columbia.edu."
            }
        ],
        "Journal": "The Journal of neuroscience : the official journal of the Society for Neuroscience",
        "PubDate": "2018"
    },
    {
        "PMID": "29794501",
        "Title": "Three-dimensional Analysis of How Radiation Affects Deep Inferior Epigastric Perforator (DIEP) Flap Volume, Projection, and Position in Breast Cancer Reconstruction.",
        "Abstract": "The deep inferior epigastric perforator (DIEP) flap has gained popularity for autologous free flap breast reconstruction. Historically, patients receiving post mastectomy radiation therapy (PMRT) were not candidates for immediate autologous reconstruction due to concerns for flap volume depletion, fat necrosis, and flap failure. However, this literature is anecdotal and lacks case controls. We objectively analyzed the effects radiation imparts on immediate DIEP flap reconstruction using 3-dimensional software and inherent controls.",
        "Keywords": [],
        "MeSH terms": [
            "Breast Neoplasms",
            "Epigastric Arteries",
            "Female",
            "Humans",
            "Imaging, Three-Dimensional",
            "Mammaplasty",
            "Mastectomy",
            "Perforator Flap",
            "Photography",
            "Radiotherapy, Adjuvant",
            "Retrospective Studies"
        ],
        "Authors": [
            {
                "First Name": "Elizabeth Stirling",
                "Last Name": "Craig",
                "Affiliation": ""
            },
            {
                "First Name": "Rachel",
                "Last Name": "Lentz",
                "Affiliation": "Section of Plastic and Reconstructive Surgery, Department of Surgery, University of California San Francisco, San Francisco, CA."
            },
            {
                "First Name": "Dhivya",
                "Last Name": "Srinivasa",
                "Affiliation": "Department of Surgery, University of Texas, Houston, TX."
            },
            {
                "First Name": "Carolyn",
                "Last Name": "Chuang",
                "Affiliation": "Yale University School of Medicine, New Haven, CT, and."
            },
            {
                "First Name": "Marc E",
                "Last Name": "Walker",
                "Affiliation": ""
            },
            {
                "First Name": "Susan A",
                "Last Name": "Higgins",
                "Affiliation": "Department of Radiation Oncology, Yale University School of Medicine, New Haven, CT."
            },
            {
                "First Name": "Jeffrey",
                "Last Name": "Salomon",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Annals of plastic surgery",
        "PubDate": "2018"
    },
    {
        "PMID": "28986463",
        "Title": "Hebbian Learning in a Random Network Captures Selectivity Properties of the Prefrontal Cortex.",
        "Abstract": "Complex cognitive behaviors, such as context-switching and rule-following, are thought to be supported by the prefrontal cortex (PFC). Neural activity in the PFC must thus be specialized to specific tasks while retaining flexibility. Nonlinear \"mixed\" selectivity is an important neurophysiological trait for enabling complex and context-dependent behaviors. Here we investigate (1) the extent to which the PFC exhibits computationally relevant properties, such as mixed selectivity, and (2) how such properties could arise via circuit mechanisms. We show that PFC cells recorded from male and female rhesus macaques during a complex task show a moderate level of specialization and structure that is not replicated by a model wherein cells receive random feedforward inputs. While random connectivity can be effective at generating mixed selectivity, the data show significantly more mixed selectivity than predicted by a model with otherwise matched parameters. A simple Hebbian learning rule applied to the random connectivity, however, increases mixed selectivity and enables the model to match the data more accurately. To explain how learning achieves this, we provide analysis along with a clear geometric interpretation of the impact of learning on selectivity. After learning, the model also matches the data on measures of noise, response density, clustering, and the distribution of selectivities. Of two styles of Hebbian learning tested, the simpler and more biologically plausible option better matches the data. These modeling results provide clues about how neural properties important for cognition can arise in a circuit and make clear experimental predictions regarding how various measures of selectivity would evolve during animal training.",
        "Keywords": [
            "mixed selectivity",
            "prefrontal cortex",
            "random connectivity",
            "theoretical models"
        ],
        "MeSH terms": [
            "Algorithms",
            "Animals",
            "Cluster Analysis",
            "Cognition",
            "Computer Simulation",
            "Female",
            "Learning",
            "Macaca mulatta",
            "Machine Learning",
            "Male",
            "Models, Neurological",
            "Neural Networks, Computer",
            "Neurons",
            "Prefrontal Cortex"
        ],
        "Authors": [
            {
                "First Name": "Grace W",
                "Last Name": "Lindsay",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons."
            },
            {
                "First Name": "Mattia",
                "Last Name": "Rigotti",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons."
            },
            {
                "First Name": "Melissa R",
                "Last Name": "Warden",
                "Affiliation": "Department of Neurobiology and Behavior, College of Agriculture and Life Sciences, Cornell University, Ithaca, New York 14853, and."
            },
            {
                "First Name": "Earl K",
                "Last Name": "Miller",
                "Affiliation": "The Picower Institute for Learning and Memory & Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons, sf2237@columbia.edu."
            }
        ],
        "Journal": "The Journal of neuroscience : the official journal of the Society for Neuroscience",
        "PubDate": "2017"
    },
    {
        "PMID": "27694992",
        "Title": "Computational principles of synaptic memory consolidation.",
        "Abstract": "Memories are stored and retained through complex, coupled processes operating on multiple timescales. To understand the computational principles behind these intricate networks of interactions, we construct a broad class of synaptic models that efficiently harness biological complexity to preserve numerous memories by protecting them against the adverse effects of overwriting. The memory capacity scales almost linearly with the number of synapses, which is a substantial improvement over the square root scaling of previous models. This was achieved by combining multiple dynamical processes that initially store memories in fast variables and then progressively transfer them to slower variables. Notably, the interactions between fast and slow variables are bidirectional. The proposed models are robust to parameter perturbations and can explain several properties of biological memory, including delayed expression of synaptic modifications, metaplasticity, and spacing effects.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Computer Simulation",
            "Memory",
            "Memory Consolidation",
            "Models, Neurological",
            "Nerve Net",
            "Neuronal Plasticity",
            "Neurons",
            "Synapses"
        ],
        "Authors": [
            {
                "First Name": "Marcus K",
                "Last Name": "Benna",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons, Columbia University, New York, New York, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons, Columbia University, New York, New York, USA."
            }
        ],
        "Journal": "Nature neuroscience",
        "PubDate": "2016"
    },
    {
        "PMID": "27557100",
        "Title": "Energy-Efficient Neuromorphic Classifiers.",
        "Abstract": "Neuromorphic engineering combines the architectural and computational principles of systems neuroscience with semiconductor electronics, with the aim of building efficient and compact devices that mimic the synaptic and neural machinery of the brain. The energy consumptions promised by neuromorphic engineering are extremely low, comparable to those of the nervous system. Until now, however, the neuromorphic approach has been restricted to relatively simple circuits and specialized functions, thereby obfuscating a direct comparison of their energy consumption to that used by conventional von Neumann digital machines solving real-world tasks. Here we show that a recent technology developed by IBM can be leveraged to realize neuromorphic circuits that operate as classifiers of complex real-world stimuli. Specifically, we provide a set of general prescriptions to enable the practical implementation of neural architectures that compete with state-of-the-art classifiers. We also show that the energy consumption of these architectures, realized on the IBM chip, is typically two or more orders of magnitude lower than that of conventional digital machines implementing classifiers with comparable performance. Moreover, the spike-based dynamics display a trade-off between integration time and accuracy, which naturally translates into algorithms that can be flexibly deployed for either fast and approximate classifications, or more accurate classifications at the mere expense of longer running times and higher energy costs. This work finally proves that the neuromorphic approach can be efficiently used in real-world applications and has significant advantages over conventional digital devices when energy consumption is considered.",
        "Keywords": [],
        "MeSH terms": [
            "Energy Metabolism",
            "Humans",
            "Neural Networks, Computer",
            "Semiconductors",
            "Support Vector Machine"
        ],
        "Authors": [
            {
                "First Name": "Daniel",
                "Last Name": "Mart\u00ed",
                "Affiliation": "D\u00e9partement d'\u00c9tudes Cognitives, \u00c9cole Normale Sup\u00e9rieure-PSL Research University, 75005 Paris, France; Institut Nationale de la Sant\u00e9 et de la Recherche M\u00e9dicale, 75005 Paris, France; and Center for Theoretical Neuroscience, Columbia University, College of Physicians and Surgeons, New York, NY 10032, U.S.A. daniel.marti@ens.fr."
            },
            {
                "First Name": "Mattia",
                "Last Name": "Rigotti",
                "Affiliation": "IBM T. J. Watson Research Center, Yorktown Heights, NY 10598, U.S.A., and Center for Theoretical Neuroscience, Columbia University, College of Physicians and Surgeons, New York, NY 10032, U.S.A. mr2666@columbia.edu."
            },
            {
                "First Name": "Mingoo",
                "Last Name": "Seok",
                "Affiliation": "Department of Electrical Engineering, Columbia University, New York, NY 10027, U.S.A. ms4415columbia.edu."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience and Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, College of Physicians and Surgeons, New York, NY 10032, U.S.A. sf2237@columbia.edu."
            }
        ],
        "Journal": "Neural computation",
        "PubDate": "2016"
    },
    {
        "PMID": "26851755",
        "Title": "Why neurons mix: high dimensionality for higher cognition.",
        "Abstract": "Neurons often respond to diverse combinations of task-relevant variables. This form of mixed selectivity plays an important computational role which is related to the dimensionality of the neural representations: high-dimensional representations with mixed selectivity allow a simple linear readout to generate a huge number of different potential responses. In contrast, neural representations based on highly specialized neurons are low dimensional and they preclude a linear readout from generating several responses that depend on multiple task-relevant variables. Here we review the conceptual and theoretical framework that explains the importance of mixed selectivity and the experimental evidence that recorded neural representations are high-dimensional. We end by discussing the implications for the design of future experiments.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Cognition",
            "Humans",
            "Models, Neurological",
            "Neurons"
        ],
        "Authors": [
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University College of Physicians and Surgeons, USA. Electronic address: sf2237@columbia.edu."
            },
            {
                "First Name": "Earl K",
                "Last Name": "Miller",
                "Affiliation": "The Picower Institute for Learning and Memory & Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, USA."
            },
            {
                "First Name": "Mattia",
                "Last Name": "Rigotti",
                "Affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, NY 10598, USA."
            }
        ],
        "Journal": "Current opinion in neurobiology",
        "PubDate": "2016"
    },
    {
        "PMID": "26053122",
        "Title": "Hippocampal-prefrontal input supports spatial encoding in working memory.",
        "Abstract": "Spatial working memory, the caching of behaviourally relevant spatial cues on a timescale of seconds, is a fundamental constituent of cognition. Although the prefrontal cortex and hippocampus are known to contribute jointly to successful spatial working memory, the anatomical pathway and temporal window for the interaction of these structures critical to spatial working memory has not yet been established. Here we find that direct hippocampal-prefrontal afferents are critical for encoding, but not for maintenance or retrieval, of spatial cues in mice. These cues are represented by the activity of individual prefrontal units in a manner that is dependent on hippocampal input only during the cue-encoding phase of a spatial working memory task. Successful encoding of these cues appears to be mediated by gamma-frequency synchrony between the two structures. These findings indicate a critical role for the direct hippocampal-prefrontal afferent pathway in the continuous updating of task-related spatial information during spatial working memory.",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Afferent Pathways",
            "Animals",
            "Cues",
            "Hippocampus",
            "Male",
            "Memory, Short-Term",
            "Mice",
            "Models, Neurological",
            "Optogenetics",
            "Prefrontal Cortex",
            "Space Perception",
            "Spatial Memory"
        ],
        "Authors": [
            {
                "First Name": "Timothy",
                "Last Name": "Spellman",
                "Affiliation": "Department of Physiology and Cellular Biophysics, Columbia University, 630 West 168th Street, New York, New York 10032, USA."
            },
            {
                "First Name": "Mattia",
                "Last Name": "Rigotti",
                "Affiliation": "1] Department of Neuroscience, Columbia University, 1051 Riverside Drive, New York, New York 10032, USA [2] IBM T. J. Watson Research Center, 1101 Kitchawan Road, Yorktown Heights, New York 10598, USA [3] Italian Academy for Advanced Studies in America, Columbia University, 1161 Amsterdam Avenue, New York, New York 10032, USA."
            },
            {
                "First Name": "Susanne E",
                "Last Name": "Ahmari",
                "Affiliation": "1] Translational Neuroscience Program, Department of Psychiatry, University of Pittsburgh, 450 Techology Drive, Pittsburgh, Pennsylvania 15219, USA [2] Center for Neuroscience and Center for the Neural Basis of Cognition, University of Pittsburgh, 200 Lothrop Drive, Pittsburgh, Pennsylvania 15261, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "1] Department of Neuroscience, Columbia University, 1051 Riverside Drive, New York, New York 10032, USA [2] Kavli Institute for Brain Sciences, Columbia University, 1051 Riverside Drive, New York, New York 10032, USA."
            },
            {
                "First Name": "Joseph A",
                "Last Name": "Gogos",
                "Affiliation": "1] Department of Physiology and Cellular Biophysics, Columbia University, 630 West 168th Street, New York, New York 10032, USA [2] Department of Neuroscience, Columbia University, 1051 Riverside Drive, New York, New York 10032, USA."
            },
            {
                "First Name": "Joshua A",
                "Last Name": "Gordon",
                "Affiliation": "1] Department of Psychiatry, Columbia University, 1051 Riverside Drive, New York, New York 10032, USA [2] Division of Integrative Neuroscience, New York State Psychiatric Institute, 1051 Riverside Drive, New York, New York 10032, USA."
            }
        ],
        "Journal": "Nature",
        "PubDate": "2015"
    },
    {
        "PMID": "25647702",
        "Title": "Blogging to bolster your plastic surgery career.",
        "Abstract": null,
        "Keywords": [],
        "MeSH terms": [
            "Blogging",
            "Career Choice",
            "Education, Medical, Continuing",
            "Humans",
            "Social Media",
            "Surgery, Plastic"
        ],
        "Authors": [
            {
                "First Name": "Anup",
                "Last Name": "Patel",
                "Affiliation": "Section of Plastic and Reconstructive Surgery, Yale University School of Medicine, New Haven, Conn."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Oluwaferanmi O",
                "Last Name": "Okanlami",
                "Affiliation": ""
            },
            {
                "First Name": "Michael",
                "Last Name": "Ditillo",
                "Affiliation": ""
            },
            {
                "First Name": "Rajendra F",
                "Last Name": "Sawh-Martinez",
                "Affiliation": ""
            }
        ],
        "Journal": "Plastic and reconstructive surgery",
        "PubDate": "2015"
    },
    {
        "PMID": "25068366",
        "Title": "Ubersense: using a free video analysis app to evaluate and improve microsurgical skills.",
        "Abstract": null,
        "Keywords": [],
        "MeSH terms": [
            "Clinical Competence",
            "Humans",
            "Internship and Residency",
            "Microsurgery",
            "Mobile Applications",
            "United States",
            "Video Recording"
        ],
        "Authors": [
            {
                "First Name": "Ajul",
                "Last Name": "Shah",
                "Affiliation": "Section of Plastic and Reconstructive Surgery, Yale University School of Medicine, New Haven, Conn."
            },
            {
                "First Name": "Megan",
                "Last Name": "Rowlands",
                "Affiliation": ""
            },
            {
                "First Name": "Anup",
                "Last Name": "Patel",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Jeffrey",
                "Last Name": "Salomon",
                "Affiliation": ""
            }
        ],
        "Journal": "Plastic and reconstructive surgery",
        "PubDate": "2014"
    },
    {
        "PMID": "24776594",
        "Title": "Don't sleep on your DIEP.",
        "Abstract": null,
        "Keywords": [],
        "MeSH terms": [
            "Female",
            "Free Tissue Flaps",
            "Humans",
            "Mammaplasty",
            "Microvessels",
            "Prone Position",
            "Sleep",
            "Venous Thrombosis"
        ],
        "Authors": [
            {
                "First Name": "Ajul",
                "Last Name": "Shah",
                "Affiliation": "Section of Plastic and Reconstructive Surgery, Yale University School of Medicine, New Haven, Conn."
            },
            {
                "First Name": "Anup",
                "Last Name": "Patel",
                "Affiliation": ""
            },
            {
                "First Name": "Chris",
                "Last Name": "Chang",
                "Affiliation": ""
            },
            {
                "First Name": "Alicia",
                "Last Name": "Wills",
                "Affiliation": ""
            },
            {
                "First Name": "Jeffrey",
                "Last Name": "Salomon",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Plastic and reconstructive surgery",
        "PubDate": "2014"
    },
    {
        "PMID": "24470389",
        "Title": "Simulated surgery and cutting guides enhance spatial positioning in free fibular mandibular reconstruction.",
        "Abstract": "The free fibular flap is the workhorse for mandibular reconstruction. Three-dimensional (3D) planning, with use of cutting guides and prebent plates, has been introduced. The purpose of this study is to evaluate the interfragmentary gap size and symmetry between conventional freehand preparation versus those using 3D planning.",
        "Keywords": [],
        "MeSH terms": [
            "Adolescent",
            "Adult",
            "Aged",
            "Aged, 80 and over",
            "Bone Plates",
            "Bone Transplantation",
            "Computer Simulation",
            "Computer-Aided Design",
            "Female",
            "Humans",
            "Imaging, Three-Dimensional",
            "Male",
            "Mandibular Reconstruction",
            "Middle Aged",
            "Retrospective Studies",
            "Surgery, Computer-Assisted",
            "Tissue and Organ Harvesting",
            "Tomography, X-Ray Computed",
            "Young Adult"
        ],
        "Authors": [
            {
                "First Name": "E",
                "Last Name": "Stirling Craig",
                "Affiliation": "Section of Plastic and Reconstructive Surgery, Department of Surgery, Yale University School of Medicine, New Haven, CT."
            },
            {
                "First Name": "Mikell",
                "Last Name": "Yuhasz",
                "Affiliation": ""
            },
            {
                "First Name": "Ajul",
                "Last Name": "Shah",
                "Affiliation": ""
            },
            {
                "First Name": "Jeffrey",
                "Last Name": "Blumberg",
                "Affiliation": ""
            },
            {
                "First Name": "Jeffrey",
                "Last Name": "Salomon",
                "Affiliation": ""
            },
            {
                "First Name": "Roger",
                "Last Name": "Lowlicht",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Derek M",
                "Last Name": "Steinbacher",
                "Affiliation": ""
            }
        ],
        "Journal": "Microsurgery",
        "PubDate": "2015"
    },
    {
        "PMID": "24255101",
        "Title": "Adult neurogenesis in the mammalian hippocampus: why the dentate gyrus?",
        "Abstract": "In the adult mammalian brain, newly generated neurons are continuously incorporated into two networks: interneurons born in the subventricular zone migrate to the olfactory bulb, whereas the dentate gyrus (DG) of the hippocampus integrates locally born principal neurons. That the rest of the mammalian brain loses significant neurogenic capacity after the perinatal period suggests that unique aspects of the structure and function of DG and olfactory bulb circuits allow them to benefit from the adult generation of neurons. In this review, we consider the distinctive features of the DG that may account for it being able to profit from this singular form of neural plasticity. Approaches to the problem of neurogenesis are grouped as \"bottom-up,\" where the phenotype of adult-born granule cells is contrasted to that of mature developmentally born granule cells, and \"top-down,\" where the impact of altering the amount of neurogenesis on behavior is examined. We end by considering the primary implications of these two approaches and future directions.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Dentate Gyrus",
            "Neurogenesis",
            "Neurons"
        ],
        "Authors": [
            {
                "First Name": "Liam J",
                "Last Name": "Drew",
                "Affiliation": "Division of Integrative Neuroscience, Research Foundation for Mental Hygiene, New York State Psychiatric Institute, New York 10032, USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Ren\u00e9",
                "Last Name": "Hen",
                "Affiliation": ""
            }
        ],
        "Journal": "Learning & memory (Cold Spring Harbor, N.Y.)",
        "PubDate": "2013"
    },
    {
        "PMID": "24047324",
        "Title": "Dynamical regimes in neural network models of matching behavior.",
        "Abstract": "The matching law constitutes a quantitative description of choice behavior that is often observed in foraging tasks. According to the matching law, organisms distribute their behavior across available response alternatives in the same proportion that reinforcers are distributed across those alternatives. Recently a few biophysically plausible neural network models have been proposed to explain the matching behavior observed in the experiments. Here we study systematically the learning dynamics of these networks while performing a matching task on the concurrent variable interval (VI) schedule. We found that the model neural network can operate in one of three qualitatively different regimes depending on the parameters that characterize the synaptic dynamics and the reward schedule: (1) a matching behavior regime, in which the probability of choosing an option is roughly proportional to the baiting fractional probability of that option; (2) a perseverative regime, in which the network tends to make always the same decision; and (3) a tristable regime, in which the network can either perseverate or choose the two targets randomly approximately with the same probability. Different parameters of the synaptic dynamics lead to different types of deviations from the matching law, some of which have been observed experimentally. We show that the performance of the network depends on the number of stable states of each synapse and that bistable synapses perform close to optimal when the proper learning rate is chosen. Because our model provides a link between synaptic dynamics and qualitatively different behaviors, this work provides us with insight into the effects of neuromodulators on adaptive behaviors and psychiatric disorders.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Brain",
            "Choice Behavior",
            "Decision Making",
            "Humans",
            "Models, Neurological",
            "Neural Networks, Computer"
        ],
        "Authors": [
            {
                "First Name": "Kiyohito",
                "Last Name": "Iigaya",
                "Affiliation": "Center for Theoretical Neuroscience, Department of Neuroscience, Columbia University Medical Center, New York, NY 10032, and Department of Physics, Columbia University, New York, NY 10027, U.S.A. ki2151@columbia.edu."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Neural computation",
        "PubDate": "2013"
    },
    {
        "PMID": "23935470",
        "Title": "Efficient partitioning of memory systems and its importance for memory consolidation.",
        "Abstract": "Long-term memories are likely stored in the synaptic weights of neuronal networks in the brain. The storage capacity of such networks depends on the degree of plasticity of their synapses. Highly plastic synapses allow for strong memories, but these are quickly overwritten. On the other hand, less labile synapses result in long-lasting but weak memories. Here we show that the trade-off between memory strength and memory lifetime can be overcome by partitioning the memory system into multiple regions characterized by different levels of synaptic plasticity and transferring memory information from the more to less plastic region. The improvement in memory lifetime is proportional to the number of memory regions, and the initial memory strength can be orders of magnitude larger than in a non-partitioned memory system. This model provides a fundamental computational reason for memory consolidation processes at the systems level.",
        "Keywords": [],
        "MeSH terms": [
            "Brain",
            "Memory",
            "Nerve Net",
            "Synapses"
        ],
        "Authors": [
            {
                "First Name": "Alex",
                "Last Name": "Roxin",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, New York, New York, United States of America."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "PLoS computational biology",
        "PubDate": "2013"
    },
    {
        "PMID": "23788143",
        "Title": "Radiation therapy and expander-implant breast reconstruction: an analysis of timing and comparison of complications.",
        "Abstract": "The optimal timing of expander-implant exchange in the setting of postmastectomy radiation therapy (PMRT) remains unclear with prior reports yielding inconsistent and variable results. The purpose of this study was to characterize complications associated with the sequencing of expander-implant breast reconstruction before or after PMRT and to compare the outcomes between early (<4 months) and late (>4 months) expander-implant exchange in the subset of patients who received PMRT before exchange.",
        "Keywords": [],
        "MeSH terms": [
            "Adult",
            "Breast Implantation",
            "Breast Implants",
            "Breast Neoplasms",
            "Female",
            "Follow-Up Studies",
            "Humans",
            "Logistic Models",
            "Mastectomy",
            "Middle Aged",
            "Multivariate Analysis",
            "Postoperative Complications",
            "Radiotherapy, Adjuvant",
            "Reoperation",
            "Retrospective Studies",
            "Time Factors",
            "Tissue Expansion",
            "Tissue Expansion Devices",
            "Treatment Outcome"
        ],
        "Authors": [
            {
                "First Name": "Rachel",
                "Last Name": "Lentz",
                "Affiliation": "Section of Plastic Surgery, Department of Surgery, Yale University School of Medicine, New Haven, CT 06519-8062, USA. Rachel.Lentz@yale.edu"
            },
            {
                "First Name": "Reuben",
                "Last Name": "Ng",
                "Affiliation": ""
            },
            {
                "First Name": "Susan A",
                "Last Name": "Higgins",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Michael",
                "Last Name": "Matthew",
                "Affiliation": ""
            },
            {
                "First Name": "Stephanie L",
                "Last Name": "Kwei",
                "Affiliation": ""
            }
        ],
        "Journal": "Annals of plastic surgery",
        "PubDate": "2013"
    },
    {
        "PMID": "23685452",
        "Title": "The importance of mixed selectivity in complex cognitive tasks.",
        "Abstract": "Single-neuron activity in the prefrontal cortex (PFC) is tuned to mixtures of multiple task-related aspects. Such mixed selectivity is highly heterogeneous, seemingly disordered and therefore difficult to interpret. We analysed the neural activity recorded in monkeys during an object sequence memory task to identify a role of mixed selectivity in subserving the cognitive functions ascribed to the PFC. We show that mixed selectivity neurons encode distributed information about all task-relevant aspects. Each aspect can be decoded from the population of neurons even when single-cell selectivity to that aspect is eliminated. Moreover, mixed selectivity offers a significant computational advantage over specialized responses in terms of the repertoire of input-output functions implementable by readout neurons. This advantage originates from the highly diverse nonlinear selectivity to mixtures of task-relevant variables, a signature of high-dimensional neural representations. Crucially, this dimensionality is predictive of animal behaviour as it collapses in error trials. Our findings recommend a shift of focus for future studies from neurons that have easily interpretable response tuning to the widely observed, but rarely analysed, mixed selectivity neurons.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Behavior, Animal",
            "Cognition",
            "Haplorhini",
            "Memory",
            "Models, Neurological",
            "Neurons",
            "Prefrontal Cortex",
            "Single-Cell Analysis"
        ],
        "Authors": [
            {
                "First Name": "Mattia",
                "Last Name": "Rigotti",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University College of Physicians and Surgeons, New York, New York 10032, USA."
            },
            {
                "First Name": "Omri",
                "Last Name": "Barak",
                "Affiliation": ""
            },
            {
                "First Name": "Melissa R",
                "Last Name": "Warden",
                "Affiliation": ""
            },
            {
                "First Name": "Xiao-Jing",
                "Last Name": "Wang",
                "Affiliation": ""
            },
            {
                "First Name": "Nathaniel D",
                "Last Name": "Daw",
                "Affiliation": ""
            },
            {
                "First Name": "Earl K",
                "Last Name": "Miller",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Nature",
        "PubDate": "2013"
    },
    {
        "PMID": "23641210",
        "Title": "Synaptic encoding of temporal contiguity.",
        "Abstract": "Often we need to perform tasks in an environment that changes stochastically. In these situations it is important to learn the statistics of sequences of events in order to predict the future and the outcome of our actions. The statistical description of many of these sequences can be reduced to the set of probabilities that a particular event follows another event (temporal contiguity). Under these conditions, it is important to encode and store in our memory these transition probabilities. Here we show that for a large class of synaptic plasticity models, the distribution of synaptic strengths encodes transitions probabilities. Specifically, when the synaptic dynamics depend on pairs of contiguous events and the synapses can remember multiple instances of the transitions, then the average synaptic weights are a monotonic function of the transition probabilities. The synaptic weights converge to the distribution encoding the probabilities also when the correlations between consecutive synaptic modifications are considered. We studied how this distribution depends on the number of synaptic states for a specific model of a multi-state synapse with hard bounds. In the case of bistable synapses, the average synaptic weights are a smooth function of the transition probabilities and the accuracy of the encoding depends on the learning rate. As the number of synaptic states increases, the average synaptic weights become a step function of the transition probabilities. We finally show that the information stored in the synaptic weights can be read out by a simple rate-based neural network. Our study shows that synapses encode transition probabilities under general assumptions and this indicates that temporal contiguity is likely to be encoded and harnessed in almost every neural circuit in the brain.",
        "Keywords": [
            "Markov processes",
            "forgetting",
            "learning and memory",
            "synaptic plasticity",
            "temporal contiguity"
        ],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Srdjan",
                "Last Name": "Ostojic",
                "Affiliation": "Department of Neuroscience, Center for Theoretical Neuroscience, Columbia University Medical Center New York, NY, USA ; Department Etudes Cognitives, CNRS, Group for Neural Theory, LNC INSERM U960, Ecole Normale Superieure Paris, France."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Frontiers in computational neuroscience",
        "PubDate": "2013"
    },
    {
        "PMID": "23622059",
        "Title": "Limber neurons for a nimble mind.",
        "Abstract": "In this issue of Neuron, Stokes et\u00a0al. (2013) demonstrate that cortical neurons that adapt their properties with task demands form patterns reflecting the shifting mental states needed to solve the task. Adaptive neurons may be critical to hallmarks of cognition: behavioral complexity and flexibility.",
        "Keywords": [],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Earl K",
                "Last Name": "Miller",
                "Affiliation": "The Picower Institute for Learning & Memory and Department of Brain & Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. ekmiller@mit.edu"
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Neuron",
        "PubDate": "2013"
    },
    {
        "PMID": "23447596",
        "Title": "The sparseness of mixed selectivity neurons controls the generalization-discrimination trade-off.",
        "Abstract": "Intelligent behavior requires integrating several sources of information in a meaningful fashion-be it context with stimulus or shape with color and size. This requires the underlying neural mechanism to respond in a different manner to similar inputs (discrimination), while maintaining a consistent response for noisy variations of the same input (generalization). We show that neurons that mix information sources via random connectivity can form an easy to read representation of input combinations. Using analytical and numerical tools, we show that the coding level or sparseness of these neurons' activity controls a trade-off between generalization and discrimination, with the optimal level depending on the task at hand. In all realistic situations that we analyzed, the optimal fraction of inputs to which a neuron responds is close to 0.1. Finally, we predict a relation between a measurable property of the neural representation and task performance.",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Animals",
            "Color Perception",
            "Discrimination, Psychological",
            "Generalization, Psychological",
            "Humans",
            "Models, Neurological",
            "Nerve Net",
            "Neurons",
            "Photic Stimulation",
            "Size Perception"
        ],
        "Authors": [
            {
                "First Name": "Omri",
                "Last Name": "Barak",
                "Affiliation": "Center for Theoretical Neuroscience, Department of Neuroscience, Columbia University Medical Center, New York, New York 10032, USA."
            },
            {
                "First Name": "Mattia",
                "Last Name": "Rigotti",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "The Journal of neuroscience : the official journal of the Society for Neuroscience",
        "PubDate": "2013"
    },
    {
        "PMID": "23096658",
        "Title": "Does the left hand know what the right hand is doing? What plastic surgeons need to know about radiation therapy techniques.",
        "Abstract": null,
        "Keywords": [],
        "MeSH terms": [
            "Breast Neoplasms",
            "Radiotherapy",
            "Radiotherapy Dosage",
            "Skin",
            "Surgery, Plastic"
        ],
        "Authors": [
            {
                "First Name": "Rachel B",
                "Last Name": "Lentz",
                "Affiliation": "Section of Plastic and Reconstructive Surgery, Department of Surgery (Lentz, Craig) Department of Therapeutic Radiology (Ross) Section of Plastic and Reconstructive Surgery, Department of Surgery (Fusi) Department of Therapeutic Radiology, Yale University School of Medicine, New Haven, Conn. (Higgins)."
            },
            {
                "First Name": "E Stirling",
                "Last Name": "Craig",
                "Affiliation": ""
            },
            {
                "First Name": "Christopher C",
                "Last Name": "Ross",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Susan A",
                "Last Name": "Higgins",
                "Affiliation": ""
            }
        ],
        "Journal": "Plastic and reconstructive surgery",
        "PubDate": "2012"
    },
    {
        "PMID": "22972954",
        "Title": "Learning selective top-down control enhances performance in a visual categorization task.",
        "Abstract": "We model the putative neuronal and synaptic mechanisms involved in learning a visual categorization task, taking inspiration from single-cell recordings in inferior temporal cortex (ITC). Our working hypothesis is that learning the categorization task involves both bottom-up, ITC to prefrontal cortex (PFC), and top-down (PFC to ITC) synaptic plasticity and that the latter enhances the selectivity of the ITC neurons encoding the task-relevant features of the stimuli, thereby improving the signal-to-noise ratio. We test this hypothesis by modeling both areas and their connections with spiking neurons and plastic synapses, ITC acting as a feature-selective layer and PFC as a category coding layer. This minimal model gives interesting clues as to properties and function of the selective feedback signal from PFC to ITC that help solving a categorization task. In particular, we show that, when the stimuli are very noisy because of a large number of nonrelevant features, the feedback structure helps getting better categorization performance and decreasing the reaction time. It also affects the speed and stability of the learning process and sharpens tuning curves of ITC neurons. Furthermore, the model predicts a modulation of neural activities during error trials, by which the differential selectivity of ITC neurons to task-relevant and task-irrelevant features diminishes or is even reversed, and modulations in the time course of neural activities that appear when, after learning, corrupted versions of the stimuli are input to the network.",
        "Keywords": [],
        "MeSH terms": [
            "Feedback",
            "Frontal Lobe",
            "Humans",
            "Learning",
            "Models, Neurological",
            "Nerve Net",
            "Neuronal Plasticity",
            "Neurons",
            "Signal-To-Noise Ratio",
            "Synapses",
            "Temporal Lobe",
            "Visual Perception"
        ],
        "Authors": [
            {
                "First Name": "Mario",
                "Last Name": "Pannunzi",
                "Affiliation": "Universitat Pompeu Fabra, Barcelona, Spain. mario.pannunzi@gmail.com"
            },
            {
                "First Name": "Guido",
                "Last Name": "Gigante",
                "Affiliation": ""
            },
            {
                "First Name": "Maurizio",
                "Last Name": "Mattia",
                "Affiliation": ""
            },
            {
                "First Name": "Gustavo",
                "Last Name": "Deco",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Paolo",
                "Last Name": "Del Giudice",
                "Affiliation": ""
            }
        ],
        "Journal": "Journal of neurophysiology",
        "PubDate": "2012"
    },
    {
        "PMID": "22903381",
        "Title": "Immediate nipple reconstruction utilizing the DIEP flap in areola-sparing mastectomy.",
        "Abstract": "The surgical treatment of breast cancer has dramatically evolved over the past decade toward an approach combining oncologic safety with aesthetic outcomes. The skin-sparing mastectomy initiated this paradigm shift amongst breast surgeons and can be oncologically safe, in some cases sparing both the areola and the nipple. In accordance with the emphasis on aesthetics, some general surgeons have adopted new methods of resecting only the nipple, sparing the areola in select patients. The superior aesthetic results, durability, and decreased donor site morbidity of perforator flaps have brought autologous reconstruction back to the forefront of breast reconstruction with the deep inferior epigastric artery perforator (DIEP) flap as the gold standard. We describe a technique utilizing the DIEP flap skin paddle for immediate nipple reconstruction at the time of mastectomy and reconstruction, eliminating the need for delayed reconstruction and limiting donor site morbidity by concealing the donor site below the mastectomy skin flaps. In the six cases described performed between 2010 and 2012 (mean with 53 years; range 46-59 years), there have been no complications to the flap or the nipple postoperatively, nor has there been a need for further nipple revisions for 6 months. The nipple position relative to the flap breast mound has remained unchanged for up to 6 months. The immediate nipple reconstruction does not significantly lengthen operative time, requiring approximately 30 additional operative minutes per nipple. Immediate nipple reconstruction utilizing the DIEP flap can be a cost-effective and feasible technique for recreating a natural-appearing and aesthetic nipple in select patients.",
        "Keywords": [],
        "MeSH terms": [
            "Breast Neoplasms",
            "Cohort Studies",
            "Female",
            "Free Tissue Flaps",
            "Humans",
            "Mammaplasty",
            "Mastectomy, Subcutaneous",
            "Middle Aged",
            "Patient Satisfaction",
            "Time Factors",
            "Treatment Outcome"
        ],
        "Authors": [
            {
                "First Name": "E Stirling",
                "Last Name": "Craig",
                "Affiliation": "Section of Plastic and Reconstructive Surgery, Department of Surgery, Yale University School of Medicine, New Haven, CT, USA. elizabeth.craig@yale.edu"
            },
            {
                "First Name": "Marc E",
                "Last Name": "Walker",
                "Affiliation": ""
            },
            {
                "First Name": "Jeffrey",
                "Last Name": "Salomon",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Microsurgery",
        "PubDate": "2013"
    },
    {
        "PMID": "22437263",
        "Title": "Venous thromboembolism risk factors in breast cancer patients undergoing deep inferior epigastric perforator flap reconstruction.",
        "Abstract": null,
        "Keywords": [],
        "MeSH terms": [
            "Breast Neoplasms",
            "Female",
            "Humans",
            "Mammaplasty",
            "Retrospective Studies",
            "Risk Factors",
            "Surgical Flaps",
            "Venous Thromboembolism"
        ],
        "Authors": [
            {
                "First Name": "E Stirling",
                "Last Name": "Craig",
                "Affiliation": ""
            },
            {
                "First Name": "Marc E",
                "Last Name": "Walker",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Microsurgery",
        "PubDate": "2012"
    },
    {
        "PMID": "21048899",
        "Title": "Internal representation of task rules by recurrent dynamics: the importance of the diversity of neural responses.",
        "Abstract": "Neural activity of behaving animals, especially in the prefrontal cortex, is highly heterogeneous, with selective responses to diverse aspects of the executed task. We propose a general model of recurrent neural networks that perform complex rule-based tasks, and we show that the diversity of neuronal responses plays a fundamental role when the behavioral responses are context-dependent. Specifically, we found that when the inner mental states encoding the task rules are represented by stable patterns of neural activity (attractors of the neural dynamics), the neurons must be selective for combinations of sensory stimuli and inner mental states. Such mixed selectivity is easily obtained by neurons that connect with random synaptic strengths both to the recurrent network and to neurons encoding sensory inputs. The number of randomly connected neurons needed to solve a task is on average only three times as large as the number of neurons needed in a network designed ad hoc. Moreover, the number of needed neurons grows only linearly with the number of task-relevant events and mental states, provided that each neuron responds to a large proportion of events (dense/distributed coding). A biologically realistic implementation of the model captures several aspects of the activity recorded from monkeys performing context-dependent tasks. Our findings explain the importance of the diversity of neural responses and provide us with simple and general principles for designing attractor neural networks that perform complex computation.",
        "Keywords": [
            "attractor neural network",
            "mixed selectivity",
            "persistent activity",
            "prefrontal cortex",
            "randomly connected neurons",
            "rule-based behavior"
        ],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Mattia",
                "Last Name": "Rigotti",
                "Affiliation": "Center for Theoretical Neuroscience, College of Physicians and Surgeons, Columbia University New York, NY, USA."
            },
            {
                "First Name": "Daniel",
                "Last Name": "Ben Dayan Rubin",
                "Affiliation": ""
            },
            {
                "First Name": "Xiao-Jing",
                "Last Name": "Wang",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Frontiers in computational neuroscience",
        "PubDate": "2010"
    },
    {
        "PMID": "20331363",
        "Title": "Emotion, cognition, and mental state representation in amygdala and prefrontal cortex.",
        "Abstract": "Neuroscientists have often described cognition and emotion as separable processes implemented by different regions of the brain, such as the amygdala for emotion and the prefrontal cortex for cognition. In this framework, functional interactions between the amygdala and prefrontal cortex mediate emotional influences on cognitive processes such as decision-making, as well as the cognitive regulation of emotion. However, neurons in these structures often have entangled representations, whereby single neurons encode multiple cognitive and emotional variables. Here we review studies using anatomical, lesion, and neurophysiological approaches to investigate the representation and utilization of cognitive and emotional parameters. We propose that these mental state parameters are inextricably linked and represented in dynamic neural networks composed of interconnected prefrontal and limbic brain structures. Future theoretical and experimental work is required to understand how these mental state representations form and how shifts between mental states occur, a critical feature of adaptive cognitive and emotional behavior.",
        "Keywords": [],
        "MeSH terms": [
            "Amygdala",
            "Cognition",
            "Emotions",
            "Mental Processes",
            "Models, Neurological",
            "Prefrontal Cortex"
        ],
        "Authors": [
            {
                "First Name": "C Daniel",
                "Last Name": "Salzman",
                "Affiliation": "Department of Neuroscience, Columbia University, New York, NY 10032, USA. cds2005@columbia.edu"
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Annual review of neuroscience",
        "PubDate": "2010"
    },
    {
        "PMID": "20100580",
        "Title": "Attractor concretion as a mechanism for the formation of context representations.",
        "Abstract": "Complex tasks often require the memory of recent events, the knowledge about the context in which they occur, and the goals we intend to reach. All this information is stored in our mental states. Given a set of mental states, reinforcement learning (RL) algorithms predict the optimal policy that maximizes future reward. RL algorithms assign a value to each already-known state so that discovering the optimal policy reduces to selecting the action leading to the state with the highest value. But how does the brain create representations of these mental states in the first place? We propose a mechanism for the creation of mental states that contain information about the temporal statistics of the events in a particular context. We suggest that the mental states are represented by stable patterns of reverberating activity, which are attractors of the neural dynamics. These representations are built from neurons that are selective to specific combinations of external events (e.g. sensory stimuli) and pre-existent mental states. Consistent with this notion, we find that neurons in the amygdala and in orbitofrontal cortex (OFC) often exhibit this form of mixed selectivity. We propose that activating different mixed selectivity neurons in a fixed temporal order modifies synaptic connections so that conjunctions of events and mental states merge into a single pattern of reverberating activity. This process corresponds to the birth of a new, different mental state that encodes a different temporal context. The concretion process depends on temporal contiguity, i.e. on the probability that a combination of an event and mental states follows or precedes the events and states that define a certain context. The information contained in the context thereby allows an animal to assign unambiguously a value to the events that initially appeared in different situations with different meanings.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Brain",
            "Cognition",
            "Humans",
            "Learning",
            "Models, Neurological",
            "Neural Networks, Computer",
            "Neurons",
            "Reinforcement, Psychology"
        ],
        "Authors": [
            {
                "First Name": "Mattia",
                "Last Name": "Rigotti",
                "Affiliation": "Department of Neuroscience, Columbia University College of Physicians and Surgeons, New York, NY 10032-2695, USA."
            },
            {
                "First Name": "Daniel",
                "Last Name": "Ben Dayan Rubin",
                "Affiliation": ""
            },
            {
                "First Name": "Sara E",
                "Last Name": "Morrison",
                "Affiliation": ""
            },
            {
                "First Name": "C Daniel",
                "Last Name": "Salzman",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "NeuroImage",
        "PubDate": "2010"
    },
    {
        "PMID": "19153762",
        "Title": "Learning flexible sensori-motor mappings in a complex network.",
        "Abstract": "Given the complex structure of the brain, how can synaptic plasticity explain the learning and forgetting of associations when these are continuously changing? We address this question by studying different reinforcement learning rules in a multilayer network in order to reproduce monkey behavior in a visuomotor association task. Our model can only reproduce the learning performance of the monkey if the synaptic modifications depend on the pre- and postsynaptic activity, and if the intrinsic level of stochasticity is low. This favored learning rule is based on reward modulated Hebbian synaptic plasticity and shows the interesting feature that the learning performance does not substantially degrade when adding layers to the network, even for a complex problem.",
        "Keywords": [],
        "MeSH terms": [
            "Algorithms",
            "Animals",
            "Brain Mapping",
            "Haplorhini",
            "Learning",
            "Mathematics",
            "Models, Neurological",
            "Neuronal Plasticity",
            "Neurons",
            "Psychomotor Performance",
            "Reward",
            "Visual Perception"
        ],
        "Authors": [
            {
                "First Name": "Eleni",
                "Last Name": "Vasilaki",
                "Affiliation": "Institute of Physiology, University of Bern, Buehlplatz 5, 3012 Bern, Switzerland. eleni.vasilaki@epfl.ch"
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Xiao-Jing",
                "Last Name": "Wang",
                "Affiliation": ""
            },
            {
                "First Name": "Walter",
                "Last Name": "Senn",
                "Affiliation": ""
            }
        ],
        "Journal": "Biological cybernetics",
        "PubDate": "2009"
    },
    {
        "PMID": "19011920",
        "Title": "The response of cortical neurons to in vivo-like input current: theory and experiment: II. Time-varying and spatially distributed inputs.",
        "Abstract": "The response of a population of neurons to time-varying synaptic inputs can show a rich phenomenology, hardly predictable from the dynamical properties of the membrane's inherent time constants. For example, a network of neurons in a state of spontaneous activity can respond significantly more rapidly than each single neuron taken individually. Under the assumption that the statistics of the synaptic input is the same for a population of similarly behaving neurons (mean field approximation), it is possible to greatly simplify the study of neural circuits, both in the case in which the statistics of the input are stationary (reviewed in La Camera et al. in Biol Cybern, 2008) and in the case in which they are time varying and unevenly distributed over the dendritic tree. Here, we review theoretical and experimental results on the single-neuron properties that are relevant for the dynamical collective behavior of a population of neurons. We focus on the response of integrate-and-fire neurons and real cortical neurons to long-lasting, noisy, in vivo-like stationary inputs and show how the theory can predict the observed rhythmic activity of cultures of neurons. We then show how cortical neurons adapt on multiple time scales in response to input with stationary statistics in vitro. Next, we review how it is possible to study the general response properties of a neural circuit to time-varying inputs by estimating the response of single neurons to noisy sinusoidal currents. Finally, we address the dendrite-soma interactions in cortical neurons leading to gain modulation and spike bursts, and show how these effects can be captured by a two-compartment integrate-and-fire neuron. Most of the experimental results reviewed in this article have been successfully reproduced by simple integrate-and-fire model neurons.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Cerebral Cortex",
            "Humans",
            "Models, Neurological",
            "Neural Networks, Computer",
            "Neurons"
        ],
        "Authors": [
            {
                "First Name": "Michele",
                "Last Name": "Giugliano",
                "Affiliation": "Laboratory of Neural Microcircuitry, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Station 15, 1015, Lausanne, Switzerland. michele.giugliano@epfl.ch"
            },
            {
                "First Name": "Giancarlo",
                "Last Name": "La Camera",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Walter",
                "Last Name": "Senn",
                "Affiliation": ""
            }
        ],
        "Journal": "Biological cybernetics",
        "PubDate": "2008"
    },
    {
        "PMID": "18985378",
        "Title": "The response of cortical neurons to in vivo-like input current: theory and experiment : I. Noisy inputs with stationary statistics.",
        "Abstract": "The study of several aspects of the collective dynamics of interacting neurons can be highly simplified if one assumes that the statistics of the synaptic input is the same for a large population of similarly behaving neurons (mean field approach). In particular, under such an assumption, it is possible to determine and study all the equilibrium points of the network dynamics when the neuronal response to noisy, in vivo-like, synaptic currents is known. The response function can be computed analytically for simple integrate-and-fire neuron models and it can be measured directly in experiments in vitro. Here we review theoretical and experimental results about the neural response to noisy inputs with stationary statistics. These response functions are important to characterize the collective neural dynamics that are proposed to be the neural substrate of working memory, decision making and other cognitive functions. Applications to the case of time-varying inputs are reviewed in a companion paper (Giugliano et al. in Biol Cybern, 2008). We conclude that modified integrate-and-fire neuron models are good enough to reproduce faithfully many of the relevant dynamical aspects of the neuronal response measured in experiments on real neurons in vitro.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Cerebral Cortex",
            "Humans",
            "Models, Neurological",
            "Neurons"
        ],
        "Authors": [
            {
                "First Name": "Giancarlo",
                "Last Name": "La Camera",
                "Affiliation": "Laboratory of Neuropsychology, National Institute of Mental Health, National Institutes of Health, 49 Convent Dr, Rm 1B80, Bethesda, MD 20892, USA. lacamerag@gmail.com"
            },
            {
                "First Name": "Michele",
                "Last Name": "Giugliano",
                "Affiliation": ""
            },
            {
                "First Name": "Walter",
                "Last Name": "Senn",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Biological cybernetics",
        "PubDate": "2008"
    },
    {
        "PMID": "18946529",
        "Title": "Long memory lifetimes require complex synapses and limited sparseness.",
        "Abstract": "Theoretical studies have shown that memories last longer if the neural representations are sparse, that is, when each neuron is selective for a small fraction of the events creating the memories. Sparseness reduces both the interference between stored memories and the number of synaptic modifications which are necessary for memory storage. Paradoxically, in cortical areas like the inferotemporal cortex, where presumably memory lifetimes are longer than in the medial temporal lobe, neural representations are less sparse. We resolve this paradox by analyzing the effects of sparseness on complex models of synaptic dynamics in which there are metaplastic states with different degrees of plasticity. For these models, memory retention in a large number of synapses across multiple neurons is significantly more efficient in case of many metaplastic states, that is, for an elevated degree of complexity. In other words, larger brain regions allow to retain memories for significantly longer times only if the synaptic complexity increases with the total number of synapses. However, the initial memory trace, the one experienced immediately after memory storage, becomes weaker both when the number of metaplastic states increases and when the neural representations become sparser. Such a memory trace must be above a given threshold in order to permit every single neuron to retrieve the information stored in its synapses. As a consequence, if the initial memory trace is reduced because of the increased synaptic complexity, then the neural representations must be less sparse. We conclude that long memory lifetimes allowed by a larger number of synapses require more complex synapses, and hence, less sparse representations, which is what is observed in the brain.",
        "Keywords": [
            "Learning",
            "Sparseness",
            "Synaptic plasticity"
        ],
        "MeSH terms": [],
        "Authors": [
            {
                "First Name": "Daniel D",
                "Last Name": "Ben Dayan Rubin",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University, NY USA."
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Frontiers in computational neuroscience",
        "PubDate": "2007"
    },
    {
        "PMID": "18339929",
        "Title": "Neuroscience. A quiescent working memory.",
        "Abstract": null,
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Brain",
            "Calcium",
            "Humans",
            "Memory",
            "Models, Neurological",
            "Neural Pathways",
            "Neuronal Plasticity",
            "Neurons",
            "Neurotransmitter Agents",
            "Synapses",
            "Synaptic Transmission"
        ],
        "Authors": [
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Theoretical Neuroscience, Columbia University College of Physicians and Surgeons, New York, NY 10032, USA. sf2237@columbia.edu"
            }
        ],
        "Journal": "Science (New York, N.Y.)",
        "PubDate": "2008"
    },
    {
        "PMID": "18263893",
        "Title": "The dynamical response properties of neocortical neurons to temporally modulated noisy inputs in vitro.",
        "Abstract": "Cortical neurons are often classified by current-frequency relationship. Such a static description is inadequate to interpret neuronal responses to time-varying stimuli. Theoretical studies suggested that single-cell dynamical response properties are necessary to interpret ensemble responses to fast input transients. Further, it was shown that input-noise linearizes and boosts the response bandwidth, and that the interplay between the barrage of noisy synaptic currents and the spike-initiation mechanisms determine the dynamical properties of the firing rate. To test these model predictions, we estimated the linear response properties of layer 5 pyramidal cells by injecting a superposition of a small-amplitude sinusoidal wave and a background noise. We characterized the evoked firing probability across many stimulation trials and a range of oscillation frequencies (1-1000 Hz), quantifying response amplitude and phase-shift while changing noise statistics. We found that neurons track unexpectedly fast transients, as their response amplitude has no attenuation up to 200 Hz. This cut-off frequency is higher than the limits set by passive membrane properties (approximately 50 Hz) and average firing rate (approximately 20 Hz) and is not affected by the rate of change of the input. Finally, above 200 Hz, the response amplitude decays as a power-law with an exponent that is independent of voltage fluctuations induced by the background noise.",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Animals",
            "Artifacts",
            "Electric Stimulation",
            "Evoked Potentials",
            "Linear Models",
            "Models, Neurological",
            "Neocortex",
            "Organ Culture Techniques",
            "Periodicity",
            "Pyramidal Cells",
            "Rats",
            "Rats, Wistar",
            "Reaction Time",
            "Somatosensory Cortex"
        ],
        "Authors": [
            {
                "First Name": "Harold",
                "Last Name": "K\u00f6ndgen",
                "Affiliation": "Department of Physiology, University of Bern, Bern CH-3012, Switzerland."
            },
            {
                "First Name": "Caroline",
                "Last Name": "Geisler",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Xiao-Jing",
                "Last Name": "Wang",
                "Affiliation": ""
            },
            {
                "First Name": "Hans-Rudolf",
                "Last Name": "L\u00fcscher",
                "Affiliation": ""
            },
            {
                "First Name": "Michele",
                "Last Name": "Giugliano",
                "Affiliation": ""
            }
        ],
        "Journal": "Cerebral cortex (New York, N.Y. : 1991)",
        "PubDate": "2008"
    },
    {
        "PMID": "17883345",
        "Title": "Learning real-world stimuli in a neural network with spike-driven synaptic dynamics.",
        "Abstract": "We present a model of spike-driven synaptic plasticity inspired by experimental observations and motivated by the desire to build an electronic hardware device that can learn to classify complex stimuli in a semisupervised fashion. During training, patterns of activity are sequentially imposed on the input neurons, and an additional instructor signal drives the output neurons toward the desired activity. The network is made of integrate-and-fire neurons with constant leak and a floor. The synapses are bistable, and they are modified by the arrival of presynaptic spikes. The sign of the change is determined by both the depolarization and the state of a variable that integrates the postsynaptic action potentials. Following the training phase, the instructor signal is removed, and the output neurons are driven purely by the activity of the input neurons weighted by the plastic synapses. In the absence of stimulation, the synapses preserve their internal state indefinitely. Memories are also very robust to the disruptive action of spontaneous activity. A network of 2000 input neurons is shown to be able to classify correctly a large number (thousands) of highly overlapping patterns (300 classes of preprocessed Latex characters, 30 patterns per class, and a subset of the NIST characters data set) and to generalize with performances that are better than or comparable to those of artificial neural networks. Finally we show that the synaptic dynamics is compatible with many of the experimental observations on the induction of long-term modifications (spike-timing-dependent plasticity and its dependence on both the postsynaptic depolarization and the frequency of pre- and postsynaptic neurons).",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Animals",
            "Calcium",
            "Computer Simulation",
            "Learning",
            "Models, Neurological",
            "Neural Networks, Computer",
            "Neuronal Plasticity",
            "Neurons",
            "Nonlinear Dynamics",
            "Probability",
            "Synapses",
            "Synaptic Transmission",
            "Time Factors"
        ],
        "Authors": [
            {
                "First Name": "Joseph M",
                "Last Name": "Brader",
                "Affiliation": "brader@cns.unibe.ch"
            },
            {
                "First Name": "Walter",
                "Last Name": "Senn",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Neural computation",
        "PubDate": "2007"
    },
    {
        "PMID": "17442251",
        "Title": "A neural circuit model of flexible sensorimotor mapping: learning and forgetting on multiple timescales.",
        "Abstract": "Volitional behavior relies on the brain's ability to remap sensory flow to motor programs whenever demanded by a changed behavioral context. To investigate the circuit basis of such flexible behavior, we have developed a biophysically based decision-making network model of spiking neurons for arbitrary sensorimotor mapping. The model quantitatively reproduces behavioral and prefrontal single-cell data from an experiment in which monkeys learn visuomotor associations that are reversed unpredictably from time to time. We show that when synaptic modifications occur on multiple timescales, the model behavior becomes flexible only when needed: slow components of learning usually dominate the decision process. However, if behavioral contexts change frequently enough, fast components of plasticity take over, and the behavior exhibits a quick forget-and-learn pattern. This model prediction is confirmed by monkey data. Therefore, our work reveals a scenario for conditional associative learning that is distinct from instant switching between sets of well-established sensorimotor associations.",
        "Keywords": [],
        "MeSH terms": [
            "Algorithms",
            "Animals",
            "Association Learning",
            "Cues",
            "Decision Making",
            "Haplorhini",
            "Learning",
            "Memory",
            "Mental Recall",
            "Models, Neurological",
            "Neural Networks, Computer",
            "Neurons",
            "Prefrontal Cortex",
            "Psychomotor Performance",
            "Synapses"
        ],
        "Authors": [
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Neurobiology and Behavior, Columbia University College of Physicians and Surgeons, New York, NY 10032, USA."
            },
            {
                "First Name": "Wael F",
                "Last Name": "Asaad",
                "Affiliation": ""
            },
            {
                "First Name": "Earl K",
                "Last Name": "Miller",
                "Affiliation": ""
            },
            {
                "First Name": "Xiao-Jing",
                "Last Name": "Wang",
                "Affiliation": ""
            }
        ],
        "Journal": "Neuron",
        "PubDate": "2007"
    },
    {
        "PMID": "17351638",
        "Title": "Limits on the memory storage capacity of bounded synapses.",
        "Abstract": "Memories maintained in patterns of synaptic connectivity are rapidly overwritten and destroyed by ongoing plasticity related to the storage of new memories. Short memory lifetimes arise from the bounds that must be imposed on synaptic efficacy in any realistic model. We explored whether memory performance can be improved by allowing synapses to traverse a large number of states before reaching their bounds, or by changing the way these bounds are imposed. In the case of hard bounds, memory lifetimes grow proportional to the square of the number of synaptic states, but only if potentiation and depression are precisely balanced. Improved performance can be obtained without fine tuning by imposing soft bounds, but this improvement is only linear with respect to the number of synaptic states. We explored several other possibilities and conclude that improving memory performance requires a more radical modification of the standard model of memory storage.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Humans",
            "Memory",
            "Models, Neurological",
            "Neuronal Plasticity",
            "Synapses"
        ],
        "Authors": [
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Center for Neurobiology and Behavior, Kolb Research Annex, Columbia University College of Physicians and Surgeons, 1051 Riverside Drive, New York, New York 10032-2695, USA."
            },
            {
                "First Name": "L F",
                "Last Name": "Abbott",
                "Affiliation": ""
            }
        ],
        "Journal": "Nature neuroscience",
        "PubDate": "2007"
    },
    {
        "PMID": "16822044",
        "Title": "Eluding oblivion with smart stochastic selection of synaptic updates.",
        "Abstract": "The variables involved in the equations that describe realistic synaptic dynamics always vary in a limited range. Their boundedness makes the synapses forgetful, not for the mere passage of time, but because new experiences overwrite old memories. The forgetting rate depends on how many synapses are modified by each new experience: many changes means fast learning and fast forgetting, whereas few changes means slow learning and long memory retention. Reducing the average number of modified synapses can extend the memory span at the price of a reduced amount of information stored when a new experience is memorized. Every trick which allows to slow down the learning process in a smart way can improve the memory performance. We review some of the tricks that allow to elude fast forgetting (oblivion). They are based on the stochastic selection of the synapses whose modifications are actually consolidated following each new experience. In practice only a randomly selected, small fraction of the synapses eligible for an update are actually modified. This allows to acquire the amount of information necessary to retrieve the memory without compromising the retention of old experiences. The fraction of modified synapses can be further reduced in a smart way by changing synapses only when it is really necessary, i.e. when the post-synaptic neuron does not respond as desired. Finally we show that such a stochastic selection emerges naturally from spike driven synaptic dynamics which read noisy pre and post-synaptic neural activities. These activities can actually be generated by a chaotic system.",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Animals",
            "Biological Clocks",
            "Computer Simulation",
            "Feedback",
            "Humans",
            "Memory",
            "Models, Neurological",
            "Models, Statistical",
            "Nerve Net",
            "Neurons",
            "Stochastic Processes",
            "Synaptic Transmission"
        ],
        "Authors": [
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Institute of Neuroinformatics, UNIZH/ETH, Wintherthurerstrasse 190, CH-8057 Zurich. fusi@ini.unizh.ch"
            },
            {
                "First Name": "Walter",
                "Last Name": "Senn",
                "Affiliation": ""
            }
        ],
        "Journal": "Chaos (Woodbury, N.Y.)",
        "PubDate": "2006"
    },
    {
        "PMID": "16807345",
        "Title": "Multiple time scales of temporal response in pyramidal and fast spiking cortical neurons.",
        "Abstract": "Neural dynamic processes correlated over several time scales are found in vivo, in stimulus-evoked as well as spontaneous activity, and are thought to affect the way sensory stimulation is processed. Despite their potential computational consequences, a systematic description of the presence of multiple time scales in single cortical neurons is lacking. In this study, we injected fast spiking and pyramidal (PYR) neurons in vitro with long-lasting episodes of step-like and noisy, in-vivo-like current. Several processes shaped the time course of the instantaneous spike frequency, which could be reduced to a small number (1-4) of phenomenological mechanisms, either reducing (adapting) or increasing (facilitating) the neuron's firing rate over time. The different adaptation/facilitation processes cover a wide range of time scales, ranging from initial adaptation (<10 ms, PYR neurons only), to fast adaptation (<300 ms), early facilitation (0.5-1 s, PYR only), and slow (or late) adaptation (order of seconds). These processes are characterized by broad distributions of their magnitudes and time constants across cells, showing that multiple time scales are at play in cortical neurons, even in response to stationary stimuli and in the presence of input fluctuations. These processes might be part of a cascade of processes responsible for the power-law behavior of adaptation observed in several preparations, and may have far-reaching computational consequences that have been recently described.",
        "Keywords": [],
        "MeSH terms": [
            "Adaptation, Physiological",
            "Algorithms",
            "Animals",
            "Cerebral Cortex",
            "Electric Stimulation",
            "Electrophysiology",
            "Female",
            "In Vitro Techniques",
            "Male",
            "Models, Neurological",
            "Models, Statistical",
            "Neurons",
            "Patch-Clamp Techniques",
            "Pyramidal Cells",
            "Rats"
        ],
        "Authors": [
            {
                "First Name": "Giancarlo",
                "Last Name": "La Camera",
                "Affiliation": "Laboratory of Neuropsychology, National Institute of Mental Health, National Institutes of Health, 49 Convent Dr, Bethesda, MD 20892-1148, USA. lacamerag@mail.nih.gov"
            },
            {
                "First Name": "Alexander",
                "Last Name": "Rauch",
                "Affiliation": ""
            },
            {
                "First Name": "David",
                "Last Name": "Thurbon",
                "Affiliation": ""
            },
            {
                "First Name": "Hans-R",
                "Last Name": "L\u00fcscher",
                "Affiliation": ""
            },
            {
                "First Name": "Walter",
                "Last Name": "Senn",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Journal of neurophysiology",
        "PubDate": "2006"
    },
    {
        "PMID": "16555071",
        "Title": "Learning to attend: modeling the shaping of selectivity in infero-temporal cortex in a categorization task.",
        "Abstract": "Recent experiments on behaving monkeys have shown that learning a visual categorization task makes the neurons in infero-temporal cortex (ITC) more selective to the task-relevant features of the stimuli (Sigala and Logothetis in Nature 415 318-320, 2002). We hypothesize that such a selectivity modulation emerges from the interaction between ITC and other cortical area, presumably the prefrontal cortex (PFC), where the previously learned stimulus categories are encoded. We propose a biologically inspired model of excitatory and inhibitory spiking neurons with plastic synapses, modified according to a reward based Hebbian learning rule, to explain the experimental results and test the validity of our hypothesis. We assume that the ITC neurons, receiving feature selective inputs, form stronger connections with the category specific neurons to which they are consistently associated in rewarded trials. After learning, the top-down influence of PFC neurons enhances the selectivity of the ITC neurons encoding the behaviorally relevant features of the stimuli, as observed in the experiments. We conclude that the perceptual representation in visual areas like ITC can be strongly affected by the interaction with other areas which are devoted to higher cognitive functions.",
        "Keywords": [],
        "MeSH terms": [
            "Algorithms",
            "Artificial Intelligence",
            "Cerebral Cortex",
            "Learning",
            "Models, Neurological",
            "Neural Pathways",
            "Neuronal Plasticity",
            "Neurons",
            "Pattern Recognition, Visual"
        ],
        "Authors": [
            {
                "First Name": "Miruna",
                "Last Name": "Szabo",
                "Affiliation": "Siemens AG, Corporate Technology, Information and Communications, Otto-Hahn-Ring 6, 81739, Munich, Germany."
            },
            {
                "First Name": "Gustavo",
                "Last Name": "Deco",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Paolo",
                "Last Name": "Del Giudice",
                "Affiliation": ""
            },
            {
                "First Name": "Maurizio",
                "Last Name": "Mattia",
                "Affiliation": ""
            },
            {
                "First Name": "Martin",
                "Last Name": "Stetter",
                "Affiliation": ""
            }
        ],
        "Journal": "Biological cybernetics",
        "PubDate": "2006"
    },
    {
        "PMID": "16105220",
        "Title": "Learning only when necessary: better memories of correlated patterns in networks with bounded synapses.",
        "Abstract": "Learning in a neuronal network is often thought of as a linear superposition of synaptic modifications induced by individual stimuli. However, since biological synapses are naturally bounded, a linear superposition would cause fast forgetting of previously acquired memories. Here we show that this forgetting can be avoided by introducing additional constraints on the synaptic and neural dynamics. We consider Hebbian plasticity of excitatory synapses. A synapse is modified only if the postsynaptic response does not match the desired output. With this learning rule, the original memory performances with unbounded weights are regained, provided that (1) there is some global inhibition, (2) the learning rate is small, and (3) the neurons can discriminate small differences in the total synaptic input (e.g., by making the neuronal threshold small compared to the total postsynaptic input). We prove in the form of a generalized perceptron convergence theorem that under these constraints, a neuron learns to classify any linearly separable set of patterns, including a wide class of highly correlated random patterns. During the learning process, excitation becomes roughly balanced by inhibition, and the neuron classifies the patterns on the basis of small differences around this balance. The fact that synapses saturate has the additional benefit that nonlinearly separable patterns, such as similar patterns with contradicting outputs, eventually generate a subthreshold response, and therefore silence neurons that cannot provide any information.",
        "Keywords": [],
        "MeSH terms": [
            "Differential Threshold",
            "Discrimination, Psychological",
            "Humans",
            "Learning",
            "Models, Neurological",
            "Nerve Net",
            "Neural Inhibition",
            "Neuronal Plasticity",
            "Neurons",
            "Nonlinear Dynamics",
            "Perception",
            "Synapses",
            "Time Factors"
        ],
        "Authors": [
            {
                "First Name": "Walter",
                "Last Name": "Senn",
                "Affiliation": "Department of Physiology, University of Bern, CH-30 Bern, Switzerland. wsenn@cns.unibe.ch"
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Neural computation",
        "PubDate": "2005"
    },
    {
        "PMID": "16089765",
        "Title": "Convergence of stochastic learning in perceptrons with binary synapses.",
        "Abstract": "The efficacy of a biological synapse is naturally bounded, and at some resolution, and is discrete at the latest level of single vesicles. The finite number of synaptic states dramatically reduce the storage capacity of a network when online learning is considered (i.e., the synapses are immediately modified by each pattern): the trace of old memories decays exponentially with the number of new memories (palimpsest property). Moreover, finding the discrete synaptic strengths which enable the classification of linearly separable patterns is a combinatorially hard problem known to be NP complete. In this paper we show that learning with discrete (binary) synapses is nevertheless possible with high probability if a randomly selected fraction of synapses is modified following each stimulus presentation (slow stochastic learning). As an additional constraint, the synapses are only changed if the output neuron does not give the desired response, as in the case of classical perceptron learning. We prove that for linearly separable classes of patterns the stochastic learning algorithm converges with arbitrary high probability in a finite number of presentations, provided that the number of neurons encoding the patterns is large enough. The stochastic learning algorithm is successfully applied to a standard classification problem of nonlinearly separable patterns by using multiple, stochastically independent output units, with an achieved performance which is comparable to the maximal ones reached for the task.",
        "Keywords": [],
        "MeSH terms": [
            "Algorithms",
            "Artificial Intelligence",
            "Computer Simulation",
            "Learning",
            "Models, Neurological",
            "Nerve Net",
            "Neural Networks, Computer",
            "Pattern Recognition, Automated",
            "Signal Processing, Computer-Assisted",
            "Stochastic Processes",
            "Synapses"
        ],
        "Authors": [
            {
                "First Name": "Walter",
                "Last Name": "Senn",
                "Affiliation": "Department of Physiology, University of Bern, CH-3012 Bern, Switzerland. wsenn@cns.unibe.ch"
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Physical review. E, Statistical, nonlinear, and soft matter physics",
        "PubDate": "2005"
    },
    {
        "PMID": "15721245",
        "Title": "Cascade models of synaptically stored memories.",
        "Abstract": "Storing memories of ongoing, everyday experiences requires a high degree of plasticity, but retaining these memories demands protection against changes induced by further activity and experience. Models in which memories are stored through switch-like transitions in synaptic efficacy are good at storing but bad at retaining memories if these transitions are likely, and they are poor at storage but good at retention if they are unlikely. We construct and study a model in which each synapse has a cascade of states with different levels of plasticity, connected by metaplastic transitions. This cascade model combines high levels of memory storage with long retention times and significantly outperforms alternative models. As a result, we suggest that memory storage requires synapses with multiple states exhibiting dynamics over a wide range of timescales, and we suggest experimental tests of this hypothesis.",
        "Keywords": [],
        "MeSH terms": [
            "Animals",
            "Humans",
            "Memory",
            "Models, Neurological",
            "Neuronal Plasticity",
            "Synapses",
            "Time Factors"
        ],
        "Authors": [
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Institute of Physiology, University of Bern, B\u00fchlplatz 5, CH-3012, Bern, Switzerland."
            },
            {
                "First Name": "Patrick J",
                "Last Name": "Drew",
                "Affiliation": ""
            },
            {
                "First Name": "L F",
                "Last Name": "Abbott",
                "Affiliation": ""
            }
        ],
        "Journal": "Neuron",
        "PubDate": "2005"
    },
    {
        "PMID": "15333209",
        "Title": "Minimal models of adapted neuronal response to in vivo-like input currents.",
        "Abstract": "Rate models are often used to study the behavior of large networks of spiking neurons. Here we propose a procedure to derive rate models that take into account the fluctuations of the input current and firing-rate adaptation, two ubiquitous features in the central nervous system that have been previously overlooked in constructing rate models. The procedure is general and applies to any model of firing unit. As examples, we apply it to the leaky integrate-and-fire (IF) neuron, the leaky IF neuron with reversal potentials, and to the quadratic IF neuron. Two mechanisms of adaptation are considered, one due to an afterhyperpolarization current and the other to an adapting threshold for spike emission. The parameters of these simple models can be tuned to match experimental data obtained from neocortical pyramidal neurons. Finally, we show how the stationary model can be used to predict the time-varying activity of a large population of adapting neurons.",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Adaptation, Physiological",
            "Animals",
            "Humans",
            "Models, Neurological",
            "Neocortex",
            "Neurons",
            "Pyramidal Cells",
            "Rats",
            "Stochastic Processes",
            "Synaptic Transmission"
        ],
        "Authors": [
            {
                "First Name": "Giancarlo",
                "Last Name": "La Camera",
                "Affiliation": "Institute of Physiology, University of Bern, CH-3012 Bern, Switzerland. lacamera@cns.unibe.ch"
            },
            {
                "First Name": "Alexander",
                "Last Name": "Rauch",
                "Affiliation": ""
            },
            {
                "First Name": "Hans-R",
                "Last Name": "L\u00fcscher",
                "Affiliation": ""
            },
            {
                "First Name": "Walter",
                "Last Name": "Senn",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Neural computation",
        "PubDate": "2004"
    },
    {
        "PMID": "15242673",
        "Title": "Modelling the formation of working memory with networks of integrate-and-fire neurons connected by plastic synapses.",
        "Abstract": "In this paper we review a series of works concerning models of spiking neurons interacting via spike-driven, plastic, Hebbian synapses, meant to implement stimulus driven, unsupervised formation of working memory (WM) states. Starting from a summary of the experimental evidence emerging from delayed matching to sample (DMS) experiments, we briefly review the attractor picture proposed to underlie WM states. We then describe a general framework for a theoretical approach to learning with synapses subject to realistic constraints and outline some general requirements to be met by a mechanism of Hebbian synaptic structuring. We argue that a stochastic selection of the synapses to be updated allows for optimal memory storage, even if the number of stable synaptic states is reduced to the extreme (bistable synapses). A description follows of models of spike-driven synapses that implement the stochastic selection by exploiting the high irregularity in the pre- and post-synaptic activity. Reasons are listed why dynamic learning, that is the process by which the synaptic structure develops under the only guidance of neural activities, driven in turn by stimuli, is hard to accomplish. We provide a 'feasibility proof' of dynamic formation of WM states in this context the beneficial role of short-term depression (STD) is illustrated. by showing how an initially unstructured network autonomously develops a synaptic structure supporting simultaneously stable spontaneous and WM states in this context the beneficial role of short-term depression (STD) is illustrated. After summarizing heuristic indications emerging from the study performed, we conclude by briefly discussing open problems and critical issues still to be clarified.",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Animals",
            "Memory, Short-Term",
            "Models, Neurological",
            "Neuronal Plasticity",
            "Neurons",
            "Synapses"
        ],
        "Authors": [
            {
                "First Name": "Paolo",
                "Last Name": "Del Giudice",
                "Affiliation": "Physics Laboratory, Istituto Superiore di Sanit\u00e0, v.le Regina Elena 299, 00161 Roma, Italy. paolo.delgiudice@iss.infn.it"
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Maurizio",
                "Last Name": "Mattia",
                "Affiliation": ""
            }
        ],
        "Journal": "Journal of physiology, Paris",
        "PubDate": "2003"
    },
    {
        "PMID": "15056709",
        "Title": "Climbing neuronal activity as an event-based cortical representation of time.",
        "Abstract": "The brain has the ability to represent the passage of time between two behaviorally relevant events. Recordings from different areas in the cortex of monkeys suggest the existence of neurons representing time by increasing (climbing) activity, which is triggered by a first event and peaks at the expected time of a second event, e.g., a visual stimulus or a reward. When the typical interval between the two events is changed, the slope of the climbing activity adapts to the new timing. We present a model in which the climbing activity results from slow firing rate adaptation in inhibitory neurons. Hebbian synaptic modifications allow for learning the new time interval by changing the degree of firing rate adaptation. This event-based representation of time is consistent with Weber's law in interval timing, according to which the error in estimating a time interval is proportional to the interval length.",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Adaptation, Physiological",
            "Animals",
            "Cerebral Cortex",
            "Haplorhini",
            "Learning",
            "Models, Neurological",
            "Neural Inhibition",
            "Neural Networks, Computer",
            "Neuronal Plasticity",
            "Neurons",
            "Predictive Value of Tests",
            "Reaction Time",
            "Reproducibility of Results",
            "Time Perception"
        ],
        "Authors": [
            {
                "First Name": "Jan",
                "Last Name": "Reutimann",
                "Affiliation": "Institute of Physiology, University of Bern, 3012 Bern, Switzerland."
            },
            {
                "First Name": "Volodya",
                "Last Name": "Yakovlev",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            },
            {
                "First Name": "Walter",
                "Last Name": "Senn",
                "Affiliation": ""
            }
        ],
        "Journal": "The Journal of neuroscience : the official journal of the Society for Neuroscience",
        "PubDate": "2004"
    },
    {
        "PMID": "12750422",
        "Title": "Neocortical pyramidal cells respond as integrate-and-fire neurons to in vivo-like input currents.",
        "Abstract": "In the intact brain neurons are constantly exposed to intense synaptic activity. This heavy barrage of excitatory and inhibitory inputs was recreated in vitro by injecting a noisy current, generated as an Ornstein-Uhlenbeck process, into the soma of rat neocortical pyramidal cells. The response to such in vivo-like currents was studied systematically by analyzing the time development of the instantaneous spike frequency, and when possible, the stationary mean spike frequency as a function of both the mean and the variance of the input current. All cells responded with an in vivo-like action potential activity with stationary statistics that could be sustained throughout long stimulation intervals (tens of seconds), provided the frequencies were not too high. The temporal evolution of the response revealed the presence of mechanisms of fast and slow spike frequency adaptation, and a medium duration mechanism of facilitation. For strong input currents, the slow adaptation mechanism made the spike frequency response nonstationary. The minimal frequencies that caused strong slow adaptation (a decrease in the spike rate by more than 1 Hz/s), were in the range 30-80 Hz and depended on the pipette solution used. The stationary response function has been fitted by two simple models of integrate-and-fire neurons endowed with a frequency-dependent modification of the input current. This accounts for all the fast and slow mechanisms of adaptation and facilitation that determine the stationary response, and proved necessary to fit the model to the experimental data. The coefficient of variability of the interspike interval was also in part captured by the model neurons, by tuning the parameters of the model to match the mean spike frequencies only. We conclude that the integrate-and-fire model with spike-frequency-dependent adaptation/facilitation is an adequate model reduction of cortical cells when the mean spike-frequency response to in vivo-like currents with stationary statistics is considered.",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Animals",
            "Female",
            "In Vitro Techniques",
            "Male",
            "Models, Biological",
            "Neocortex",
            "Neurons",
            "Pyramidal Cells",
            "Rats",
            "Rats, Wistar"
        ],
        "Authors": [
            {
                "First Name": "Alexander",
                "Last Name": "Rauch",
                "Affiliation": "Institute of Physiology, University of Bern, 3012 Bern, Switzerland."
            },
            {
                "First Name": "Giancarlo",
                "Last Name": "La Camera",
                "Affiliation": ""
            },
            {
                "First Name": "Hans-Rudolf",
                "Last Name": "Luscher",
                "Affiliation": ""
            },
            {
                "First Name": "Walter",
                "Last Name": "Senn",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Journal of neurophysiology",
        "PubDate": "2003"
    },
    {
        "PMID": "12689388",
        "Title": "Event-driven simulation of spiking neurons with stochastic dynamics.",
        "Abstract": "We present a new technique, based on a proposed event-based strategy (Mattia & Del Giudice, 2000), for efficiently simulating large networks of simple model neurons. The strategy was based on the fact that interactions among neurons occur by means of events that are well localized in time (the action potentials) and relatively rare. In the interval between two of these events, the state variables associated with a model neuron or a synapse evolved deterministically and in a predictable way. Here, we extend the event-driven simulation strategy to the case in which the dynamics of the state variables in the inter-event intervals are stochastic. This extension captures both the situation in which the simulated neurons are inherently noisy and the case in which they are embedded in a very large network and receive a huge number of random synaptic inputs. We show how to effectively include the impact of large background populations into neuronal dynamics by means of the numerical evaluation of the statistical properties of single-model neurons under random current injection. The new simulation strategy allows the study of networks of interacting neurons with an arbitrary number of external afferents and inherent stochastic dynamics.",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Algorithms",
            "Computer Simulation",
            "Evoked Potentials",
            "Models, Neurological",
            "Motor Neurons",
            "Neurons, Afferent",
            "Stochastic Processes"
        ],
        "Authors": [
            {
                "First Name": "Jan",
                "Last Name": "Reutimann",
                "Affiliation": "Computational Neuroscience, Institute of Physiology, University of Bern, Switzerland. jan.reutimann@cns.unibe.ch"
            },
            {
                "First Name": "Michele",
                "Last Name": "Giugliano",
                "Affiliation": ""
            },
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": ""
            }
        ],
        "Journal": "Neural computation",
        "PubDate": "2003"
    },
    {
        "PMID": "12461635",
        "Title": "Hebbian spike-driven synaptic plasticity for learning patterns of mean firing rates.",
        "Abstract": "Synaptic plasticity is believed to underlie the formation of appropriate patterns of connectivity that stabilize stimulus-selective reverberations in the cortex. Here we present a general quantitative framework for studying the process of learning and memorizing of patterns of mean spike rates. General considerations based on the limitations of material (biological or electronic) synaptic devices show that most learning networks share the palimpsest property: old stimuli are forgotten to make room for the new ones. In order to prevent too-fast forgetting, one can introduce a stochastic mechanism for selecting only a small fraction of synapses to be changed upon the presentation of a stimulus. Such a mechanism can be easily implemented by exploiting the noisy fluctuations in the pre- and postsynaptic activities to be encoded. The spike-driven synaptic dynamics described here can implement such a selection mechanism to achieve slow learning, which is shown to maximize the performance of the network as an associative memory.",
        "Keywords": [],
        "MeSH terms": [
            "Action Potentials",
            "Animals",
            "Learning",
            "Mathematics",
            "Memory",
            "Nerve Net",
            "Neuronal Plasticity",
            "Neurons",
            "Synapses",
            "Time Factors"
        ],
        "Authors": [
            {
                "First Name": "Stefano",
                "Last Name": "Fusi",
                "Affiliation": "Institute of Physiology, University of Bern, B\u00fchlplatz 5, 3012 Bern, Switzerland. fusi@cns.unibe.ch"
            }
        ],
        "Journal": "Biological cybernetics",
        "PubDate": "2002"
    }
]